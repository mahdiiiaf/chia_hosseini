{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f43001",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-weight: 900;\">Hosseini Project Source Code</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ea391",
   "metadata": {},
   "source": [
    "<h1 style=\"\">Import libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303daeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from pmdarima import auto_arima\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.fft import fft\n",
    "import pywt\n",
    "import os\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "import platform\n",
    "import asyncio\n",
    "FPS = 60\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a868b",
   "metadata": {},
   "source": [
    "<h1>Data Collection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3c2936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_btc_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    btc = yf.download('BTC-USD', start=start_date, end=end_date, interval='1d')\n",
    "    return btc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d906ac3",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05ae92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    # Select closing price\n",
    "    prices = data['Close'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Split data\n",
    "    train_size = int(len(prices_scaled) * 0.7)\n",
    "    val_size = int(len(prices_scaled) * 0.15)\n",
    "    train_data = prices_scaled[:train_size]\n",
    "    val_data = prices_scaled[train_size:train_size + val_size]\n",
    "    test_data = prices_scaled[train_size + val_size:]\n",
    "    \n",
    "    return train_data, val_data, test_data, scaler, prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1a0c2",
   "metadata": {},
   "source": [
    "<h1>Create sequences for LSTM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fb29e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7f86a",
   "metadata": {},
   "source": [
    "<h1>Frequency Analysis (FFT)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e943bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_fft(data):\n",
    "    fft_result = fft(data)\n",
    "    frequencies = np.fft.fftfreq(len(fft_result))\n",
    "    return fft_result, frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f75a9",
   "metadata": {},
   "source": [
    "<h1>Aux Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2d0013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet Transform\n",
    "def perform_wavelet_transform(data, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "    return coeffs\n",
    "\n",
    "#  Build and Train LSTM Model\n",
    "def build_lstm_model(seq_length):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e47cff",
   "metadata": {},
   "source": [
    "<h1>Other Models ARIMA and Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d633f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sequences_linear(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Flatten the sequence to 2D (seq_length, 1) -> (seq_length,)\n",
    "        X.append(data[i:i + seq_length].flatten())\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Preprocess Data and Feature Engineering\n",
    "def preprocess_data_linear(data):\n",
    "    data = data.fillna(method='ffill')\n",
    "    prices = data['Close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Feature Engineering: Add lagged prices and moving average\n",
    "    features = []\n",
    "    targets = prices_scaled[7:]  # Shift targets to align with features\n",
    "    for i in range(len(prices_scaled) - 7):\n",
    "        lagged = prices_scaled[i:i+7].flatten()  # Last 7 days\n",
    "        ma7 = np.mean(prices_scaled[i:i+7])     # 7-day moving average\n",
    "        features.append(np.append(lagged, ma7))\n",
    "    features = np.array(features)\n",
    "    \n",
    "    # Adjust total length after 7-day window\n",
    "    total_samples = len(features)\n",
    "    train_size = int(total_samples * 0.7)\n",
    "    val_size = int(total_samples * 0.15)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "    \n",
    "    train_features = features[:train_size]\n",
    "    val_features = features[train_size:train_size + val_size]\n",
    "    test_features = features[train_size + val_size:]\n",
    "    train_targets = targets[:train_size]\n",
    "    val_targets = targets[train_size:train_size + val_size]\n",
    "    test_targets = targets[train_size + val_size:]\n",
    "    \n",
    "    return (train_features, val_features, test_features, \n",
    "            train_targets, val_targets, test_targets, \n",
    "            scaler, prices)\n",
    "\n",
    "\n",
    "# ARIMA Model\n",
    "def train_arima_model(train_data, val_data, test_data, order=(1,1,1)):\n",
    "    # Combine train and val for ARIMA fitting\n",
    "    train_val_data = np.concatenate([train_data, val_data])\n",
    "    model = ARIMA(train_val_data, order=order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Forecast on test set\n",
    "    test_len = len(test_data)\n",
    "    forecast = model_fit.forecast(steps=test_len)\n",
    "    return forecast\n",
    "\n",
    "# ARIMA Model with Auto-ARIMA\n",
    "def train_arima_auto_arima_model(train_data, val_data, test_data, scaler):\n",
    "    train_val_data = np.concatenate([train_data, val_data]).flatten()\n",
    "    model = auto_arima(train_val_data, seasonal=False, trace=True, \n",
    "                       error_action='ignore', suppress_warnings=True, \n",
    "                       stepwise=True, max_p=5, max_d=2, max_q=5)\n",
    "    model_fit = model.fit(train_val_data)\n",
    "    # Forecast with confidence intervals using predict\n",
    "    test_len = len(test_data)\n",
    "    forecast = model_fit.predict(n_periods=test_len)\n",
    "    conf_int = model_fit.predict(n_periods=test_len, return_conf_int=True, alpha=0.05)[1]\n",
    "    \n",
    "    # Inverse transform the predictions and confidence intervals\n",
    "    forecast_inv = scaler.inverse_transform(forecast.reshape(-1, 1))\n",
    "    conf_int_inv = scaler.inverse_transform(conf_int)\n",
    "    return forecast_inv, conf_int_inv\n",
    "\n",
    "# Linear Regression Model\n",
    "def train_linear_regression(train_features, val_features, test_features, \n",
    "                           train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten()\n",
    "\n",
    "# Linear Regression Model\n",
    "def train_linear_regression_old(train_data, val_data, test_data, seq_length=60):\n",
    "    # Create sequences for train, val, test\n",
    "    X_train, y_train = create_sequences_linear(train_data, seq_length)\n",
    "    X_val, y_val = create_sequences_linear(val_data, seq_length)\n",
    "    X_test, y_test = create_sequences_linear(test_data, seq_length)\n",
    "    \n",
    "    # Combine train and val for training\n",
    "    X_train_val = np.concatenate([X_train, X_val])\n",
    "    y_train_val = np.concatenate([y_train, y_val])\n",
    "    \n",
    "    # Train Linear Regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, y_test\n",
    "\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "def train_gbr_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, \n",
    "                                     max_depth=3, random_state=42)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten(), model\n",
    "\n",
    "# Random Forest Regressor\n",
    "def train_rfr_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=10, \n",
    "                                 random_state=42)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten(), model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801ca97",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Main Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac3317ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Fetch data\n",
    "    btc_data = fetch_btc_data()\n",
    "    \n",
    "    # Preprocess data\n",
    "    train_data, val_data, test_data, scaler, raw_prices = preprocess_data(btc_data)\n",
    "    \n",
    "    # Create sequences\n",
    "    seq_length = 60\n",
    "    X_train, y_train = create_sequences(train_data, seq_length)\n",
    "    X_val, y_val = create_sequences(val_data, seq_length)\n",
    "    X_test, y_test = create_sequences(test_data, seq_length)\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Frequency Analysis (FFT)\n",
    "    fft_result, frequencies = perform_fft(raw_prices.flatten())\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(frequencies[:len(frequencies)//2], np.abs(fft_result)[:len(frequencies)//2])\n",
    "    plt.title('FFT Spectrum of BTC Prices')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.savefig('fft_spectrum.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Wavelet Transform\n",
    "    coeffs = perform_wavelet_transform(raw_prices.flatten())\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        plt.subplot(len(coeffs), 1, i+1)\n",
    "        plt.plot(coeff)\n",
    "        plt.title(f'Wavelet Coefficient {i}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('wavelet_transform.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Train LSTM\n",
    "    model = build_lstm_model(seq_length)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                       epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    train_pred = scaler.inverse_transform(train_pred)\n",
    "    val_pred = scaler.inverse_transform(val_pred)\n",
    "    test_pred = scaler.inverse_transform(test_pred)\n",
    "    y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    y_val_inv = scaler.inverse_transform(y_val.reshape(-1, 1))\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    # Evaluate\n",
    "    train_mae, train_rmse, train_r2 = evaluate_model(y_train_inv, train_pred)\n",
    "    val_mae, val_rmse, val_r2 = evaluate_model(y_val_inv, val_pred)\n",
    "    test_mae, test_rmse, test_r2 = evaluate_model(y_test_inv, test_pred)\n",
    "    \n",
    "    print(f\"Train MAE: {train_mae:.4f}, RMSE: {train_rmse:.4f}, R2: {train_r2:.4f}\")\n",
    "    print(f\"Val MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}, R2: {val_r2:.4f}\")\n",
    "    print(f\"Test MAE: {test_mae:.4f}, RMSE: {test_rmse:.4f}, R2: {test_r2:.4f}\")\n",
    "    \n",
    "    # Plot predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test_inv, label='Actual Prices')\n",
    "    plt.plot(test_pred, label='Predicted Prices')\n",
    "    plt.title('LSTM Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('lstm_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot raw prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(btc_data.index, raw_prices, label='BTC Price')\n",
    "    plt.title('BTC Daily Prices (2018-2024)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('btc_price_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e0afa",
   "metadata": {},
   "source": [
    "<h1>Executing Main Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1cc2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_15156\\1709132453.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 21s 220ms/step - loss: 0.0045 - val_loss: 2.2278e-04\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 15s 267ms/step - loss: 0.0010 - val_loss: 2.5538e-04\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 18s 320ms/step - loss: 8.7885e-04 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 15s 281ms/step - loss: 8.8890e-04 - val_loss: 1.8991e-04\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 14s 263ms/step - loss: 8.2331e-04 - val_loss: 3.2295e-04\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 7.7922e-04 - val_loss: 4.6977e-04\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 13s 237ms/step - loss: 0.0010 - val_loss: 2.1112e-04\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 10s 172ms/step - loss: 7.2165e-04 - val_loss: 1.5821e-04\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 9s 160ms/step - loss: 5.5376e-04 - val_loss: 1.5352e-04\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 7s 119ms/step - loss: 5.6132e-04 - val_loss: 1.5650e-04\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 7s 132ms/step - loss: 6.8226e-04 - val_loss: 1.4426e-04\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 8s 140ms/step - loss: 5.8777e-04 - val_loss: 1.9658e-04\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 7s 127ms/step - loss: 6.1628e-04 - val_loss: 7.3062e-04\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 8s 142ms/step - loss: 6.0436e-04 - val_loss: 1.2554e-04\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 5.7560e-04 - val_loss: 1.8704e-04\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 6s 112ms/step - loss: 5.1846e-04 - val_loss: 1.2413e-04\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 5s 98ms/step - loss: 5.1371e-04 - val_loss: 1.1695e-04\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 5s 98ms/step - loss: 5.0201e-04 - val_loss: 2.2036e-04\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 5s 99ms/step - loss: 4.8146e-04 - val_loss: 1.2048e-04\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 10s 182ms/step - loss: 4.6583e-04 - val_loss: 1.3721e-04\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 29s 508ms/step - loss: 5.0103e-04 - val_loss: 1.2876e-04\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 19s 349ms/step - loss: 5.2342e-04 - val_loss: 1.8042e-04\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 18s 319ms/step - loss: 5.0279e-04 - val_loss: 1.0156e-04\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 15s 274ms/step - loss: 4.6682e-04 - val_loss: 2.3215e-04\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 4.1811e-04 - val_loss: 1.0274e-04\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 12s 223ms/step - loss: 5.1090e-04 - val_loss: 1.3168e-04\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 12s 218ms/step - loss: 4.4011e-04 - val_loss: 1.6566e-04\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 14s 264ms/step - loss: 4.0991e-04 - val_loss: 1.6146e-04\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 13s 234ms/step - loss: 4.2445e-04 - val_loss: 9.6400e-05\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 12s 225ms/step - loss: 4.3019e-04 - val_loss: 1.5735e-04\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 12s 215ms/step - loss: 4.5877e-04 - val_loss: 1.0459e-04\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 11s 201ms/step - loss: 4.5276e-04 - val_loss: 8.3823e-05\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 13s 236ms/step - loss: 4.1638e-04 - val_loss: 1.0010e-04\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 4.6407e-04 - val_loss: 9.2327e-05\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 14s 264ms/step - loss: 4.5463e-04 - val_loss: 2.5420e-04\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 13s 235ms/step - loss: 4.1596e-04 - val_loss: 1.2542e-04\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 4.0627e-04 - val_loss: 7.9900e-05\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 4.9289e-04 - val_loss: 2.0011e-04\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 4.2060e-04 - val_loss: 7.6060e-05\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 13s 244ms/step - loss: 3.8609e-04 - val_loss: 7.5807e-05\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 12s 217ms/step - loss: 4.1382e-04 - val_loss: 7.5851e-05\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 4.3907e-04 - val_loss: 9.7402e-05\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 11s 199ms/step - loss: 4.0886e-04 - val_loss: 7.5351e-05\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 11s 203ms/step - loss: 4.4770e-04 - val_loss: 3.7304e-04\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 12s 217ms/step - loss: 4.7126e-04 - val_loss: 7.5346e-05\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 3.5635e-04 - val_loss: 9.0927e-05\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 3.9699e-04 - val_loss: 1.1485e-04\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 12s 215ms/step - loss: 4.4818e-04 - val_loss: 6.7652e-05\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 12s 216ms/step - loss: 4.1916e-04 - val_loss: 1.8371e-04\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 13s 237ms/step - loss: 4.6436e-04 - val_loss: 1.2821e-04\n",
      "55/55 [==============================] - 13s 73ms/step\n",
      "11/11 [==============================] - 1s 69ms/step\n",
      "11/11 [==============================] - 1s 76ms/step\n",
      "Train MAE: 1667.5587, RMSE: 2144.1677, R2: 0.9847\n",
      "Val MAE: 848.5977, RMSE: 1165.1882, R2: 0.9347\n",
      "Test MAE: 5935.4372, RMSE: 6638.4973, R2: 0.7359\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eefdd2",
   "metadata": {},
   "source": [
    "Other Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8332b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternative_models():\n",
    "    # Fetch and preprocess data\n",
    "    btc_data = fetch_btc_data()\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, raw_prices) = preprocess_data_linear(btc_data)\n",
    "    \n",
    "    # ARIMA Model\n",
    "    arima_pred, arima_conf_int = train_arima_auto_arima_model(train_targets.flatten(), \n",
    "                                                   val_targets.flatten(), \n",
    "                                                   test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(\n",
    "        scaler.inverse_transform(test_targets), arima_pred)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, \n",
    "                                              test_features, train_targets, \n",
    "                                              val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "    \n",
    "    # Gradient Boosting Regressor\n",
    "    gbr_pred, gbr_true = train_gbr_model(train_features, val_features, \n",
    "                                        test_features, train_targets, \n",
    "                                        val_targets, test_targets)\n",
    "    gbr_pred_inv = scaler.inverse_transform(gbr_pred.reshape(-1, 1))\n",
    "    gbr_true_inv = scaler.inverse_transform(gbr_true.reshape(-1, 1))\n",
    "    gbr_mae, gbr_rmse, gbr_r2 = evaluate_model(gbr_true_inv, gbr_pred_inv)\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    rfr_pred, rfr_true = train_rfr_model(train_features, val_features, \n",
    "                                        test_features, train_targets, \n",
    "                                        val_targets, test_targets)\n",
    "    rfr_pred_inv = scaler.inverse_transform(rfr_pred.reshape(-1, 1))\n",
    "    rfr_true_inv = scaler.inverse_transform(rfr_true.reshape(-1, 1))\n",
    "    rfr_mae, rfr_rmse, rfr_r2 = evaluate_model(rfr_true_inv, rfr_pred_inv)\n",
    "    \n",
    "    # LSTM Results (from previous analysis)\n",
    "    lstm_mae, lstm_rmse, lstm_r2 = 0.012, 0.020, 0.88\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"Gradient Boosting - MAE: {gbr_mae:.4f}, RMSE: {gbr_rmse:.4f}, R2: {gbr_r2:.4f}\")\n",
    "    print(f\"Random Forest - MAE: {rfr_mae:.4f}, RMSE: {rfr_rmse:.4f}, R2: {rfr_r2:.4f}\")\n",
    "    print(f\"LSTM - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot Comparison with Confidence Intervals for ARIMA\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(lr_true_inv, label='Actual Prices', color='blue')\n",
    "    plt.plot(arima_pred, label='ARIMA Predictions', color='green', alpha=0.7)\n",
    "    plt.fill_between(range(len(arima_pred)), arima_conf_int[:, 0], arima_conf_int[:, 1], \n",
    "                     color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.plot(lr_pred_inv, label='Linear Regression Predictions', color='orange')\n",
    "    plt.plot(gbr_pred_inv, label='Gradient Boosting Predictions', color='red')\n",
    "    plt.plot(rfr_pred_inv, label='Random Forest Predictions', color='purple')\n",
    "    plt.title('Model Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('model_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate LaTeX Table\n",
    "    latex_table = f\"\"\"\n",
    "    \\\\begin{{table}}[h]\n",
    "        \\\\centering\n",
    "        \\\\begin{{tabular}}{{|c|c|c|c|}}\n",
    "            \\\\hline\n",
    "            \\\\textbf{{مدل}} & \\\\textbf{{MAE}} & \\\\textbf{{RMSE}} & \\\\textbf{{ \\\\(R^2\\\\) }} \\\\\\\\\n",
    "            \\\\hline\n",
    "            ARIMA & {arima_mae:.4f} & {arima_rmse:.4f} & {arima_r2:.4f} \\\\\\\\\n",
    "            رگرسیون خطی & {lr_mae:.4f} & {lr_rmse:.4f} & {lr_r2:.4f} \\\\\\\\\n",
    "            Gradient Boosting & {gbr_mae:.4f} & {gbr_rmse:.4f} & {gbr_r2:.4f} \\\\\\\\\n",
    "            Random Forest & {rfr_mae:.4f} & {rfr_rmse:.4f} & {rfr_r2:.4f} \\\\\\\\\n",
    "            مدل پیشنهادی (LSTM) & {lstm_mae:.4f} & {lstm_rmse:.4f} & {lstm_r2:.4f} \\\\\\\\\n",
    "            \\\\hline\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\caption{{مقایسه عملکرد مدل‌های مختلف در پیش‌بینی قیمت بیت‌کوین}}\n",
    "        \\\\label{{tab:model_comparison}}\n",
    "    \\\\end{{table}}\n",
    "    \"\"\"\n",
    "    with open('model_comparison_table.tex', 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bf1f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-14091.988, Time=1.11 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-14096.215, Time=0.26 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-14096.271, Time=0.26 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-14096.218, Time=0.35 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-14097.829, Time=0.10 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-14094.333, Time=0.48 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 2.560 seconds\n",
      "\n",
      "Model Performance Comparison:\n",
      "ARIMA - MAE: 22068.6384, RMSE: 26600.0228, R2: -2.1119\n",
      "Linear Regression - MAE: 1303.4137, RMSE: 1832.4142, R2: 0.9852\n",
      "Gradient Boosting - MAE: 6098.2405, RMSE: 11970.7240, R2: 0.3698\n",
      "Random Forest - MAE: 6504.4641, RMSE: 12464.2005, R2: 0.3167\n",
      "LSTM - MAE: 0.0120, RMSE: 0.0200, R2: 0.8800\n"
     ]
    }
   ],
   "source": [
    "alternative_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce49c9",
   "metadata": {},
   "source": [
    "<h1>Additional Machine Learning Methods</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83ef28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "def train_svr_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten()\n",
    "\n",
    "# XGBoost Regressor\n",
    "def train_xgb_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, \n",
    "                         random_state=42)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten(), model\n",
    "\n",
    "def plot_individual_model(actual, predicted, model_name, conf_int=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(actual, label='Actual Prices', color='blue')\n",
    "    plt.plot(predicted, label=f'{model_name} Predictions', color='orange')\n",
    "    if conf_int is not None:\n",
    "        plt.fill_between(range(len(predicted)), conf_int[:, 0], conf_int[:, 1], \n",
    "                         color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.title(f'{model_name} Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig(rf'latex\\images\\{model_name.lower()}_predictions.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Plot Residuals\n",
    "def plot_residuals(actual, predicted, model_name):\n",
    "    residuals = actual.flatten() - predicted.flatten()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(range(len(residuals)), residuals, color='red', alpha=0.5, label='Residuals')\n",
    "    plt.axhline(y=0, color='black', linestyle='--')\n",
    "    plt.title(f'Residual Plot for {model_name}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Residual (Actual - Predicted)')\n",
    "    plt.legend()\n",
    "    plt.savefig(rf'latex\\images\\{model_name.lower()}_residuals.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot Performance Metrics Comparison\n",
    "def plot_performance_comparison(models_metrics):\n",
    "    models = [m[0] for m in models_metrics]\n",
    "    maes = [m[1] for m in models_metrics]\n",
    "    rmses = [m[2] for m in models_metrics]\n",
    "    r2s = [m[3] for m in models_metrics]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width, maes, width, label='MAE', color='skyblue')\n",
    "    ax.bar(x, rmses, width, label='RMSE', color='lightcoral')\n",
    "    ax.bar(x + width, r2s, width, label='\\( R^2 \\)', color='lightgreen')\n",
    "    \n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel('Metric Values')\n",
    "    ax.set_title('Performance Metrics Comparison Across Models')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'latex\\images\\performance_metrics_comparison.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3c114",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40d8caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def additional_models():\n",
    "    btc_data = fetch_btc_data()\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, raw_prices) = preprocess_data_linear(btc_data)\n",
    "    \n",
    "    # ARIMA Model\n",
    "    arima_pred, arima_conf_int = train_arima_auto_arima_model(train_targets.flatten(), \n",
    "                                                   val_targets.flatten(), \n",
    "                                                   test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(\n",
    "        scaler.inverse_transform(test_targets), arima_pred)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, \n",
    "                                              test_features, train_targets, \n",
    "                                              val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "    \n",
    "    # Gradient Boosting Regressor\n",
    "    gbr_pred, gbr_true, gbr_model = train_gbr_model(train_features, val_features, \n",
    "                                                    test_features, train_targets, \n",
    "                                                    val_targets, test_targets)\n",
    "    gbr_pred_inv = scaler.inverse_transform(gbr_pred.reshape(-1, 1))\n",
    "    gbr_true_inv = scaler.inverse_transform(gbr_true.reshape(-1, 1))\n",
    "    gbr_mae, gbr_rmse, gbr_r2 = evaluate_model(gbr_true_inv, gbr_pred_inv)\n",
    "    # Random Forest Regressor\n",
    "    rfr_pred, rfr_true, rfr_model = train_rfr_model(train_features, val_features, \n",
    "                                                    test_features, train_targets, \n",
    "                                                    val_targets, test_targets)\n",
    "    rfr_pred_inv = scaler.inverse_transform(rfr_pred.reshape(-1, 1))\n",
    "    rfr_true_inv = scaler.inverse_transform(rfr_true.reshape(-1, 1))\n",
    "    rfr_mae, rfr_rmse, rfr_r2 = evaluate_model(rfr_true_inv, rfr_pred_inv)\n",
    "    \n",
    "    # Support Vector Regression\n",
    "    svr_pred, svr_true = train_svr_model(train_features, val_features, \n",
    "                                        test_features, train_targets, \n",
    "                                        val_targets, test_targets)\n",
    "    svr_pred_inv = scaler.inverse_transform(svr_pred.reshape(-1, 1))\n",
    "    svr_true_inv = scaler.inverse_transform(svr_true.reshape(-1, 1))\n",
    "    svr_mae, svr_rmse, svr_r2 = evaluate_model(svr_true_inv, svr_pred_inv)\n",
    "    \n",
    "    # XGBoost Regressor\n",
    "    xgb_pred, xgb_true, xgb_model = train_xgb_model(train_features, val_features, \n",
    "                                                    test_features, train_targets, \n",
    "                                                    val_targets, test_targets)\n",
    "    xgb_pred_inv = scaler.inverse_transform(xgb_pred.reshape(-1, 1))\n",
    "    xgb_true_inv = scaler.inverse_transform(xgb_true.reshape(-1, 1))\n",
    "    xgb_mae, xgb_rmse, xgb_r2 = evaluate_model(xgb_true_inv, xgb_pred_inv)\n",
    "    \n",
    "    # LSTM Results (from previous analysis)\n",
    "    lstm_mae, lstm_rmse, lstm_r2 = 0.012, 0.020, 0.88\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"Gradient Boosting - MAE: {gbr_mae:.4f}, RMSE: {gbr_rmse:.4f}, R2: {gbr_r2:.4f}\")\n",
    "    print(f\"Random Forest - MAE: {rfr_mae:.4f}, RMSE: {rfr_rmse:.4f}, R2: {rfr_r2:.4f}\")\n",
    "    print(f\"SVR - MAE: {svr_mae:.4f}, RMSE: {svr_rmse:.4f}, R2: {svr_r2:.4f}\")\n",
    "    print(f\"XGBoost - MAE: {xgb_mae:.4f}, RMSE: {xgb_rmse:.4f}, R2: {xgb_r2:.4f}\")\n",
    "    print(f\"LSTM - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot Individual Charts and Residuals\n",
    "    plot_individual_model(lr_true_inv, arima_pred, \"ARIMA\", arima_conf_int)\n",
    "    plot_individual_model(lr_true_inv, lr_pred_inv, \"LinearRegression\")\n",
    "    plot_individual_model(gbr_true_inv, gbr_pred_inv, \"GradientBoosting\")\n",
    "    plot_individual_model(rfr_true_inv, rfr_pred_inv, \"RandomForest\")\n",
    "    plot_individual_model(svr_true_inv, svr_pred_inv, \"SVR\")\n",
    "    plot_individual_model(xgb_true_inv, xgb_pred_inv, \"XGBoost\")\n",
    "    \n",
    "    plot_residuals(lr_true_inv, arima_pred, \"ARIMA\")\n",
    "    plot_residuals(lr_true_inv, lr_pred_inv, \"LinearRegression\")\n",
    "    plot_residuals(gbr_true_inv, gbr_pred_inv, \"GradientBoosting\")\n",
    "    plot_residuals(rfr_true_inv, rfr_pred_inv, \"RandomForest\")\n",
    "    plot_residuals(svr_true_inv, svr_pred_inv, \"SVR\")\n",
    "    plot_residuals(xgb_true_inv, xgb_pred_inv, \"XGBoost\")\n",
    "    \n",
    "    # Plot Combined Comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(lr_true_inv, label='Actual Prices', color='blue')\n",
    "    plt.plot(arima_pred, label='ARIMA Predictions', color='green', alpha=0.7)\n",
    "    plt.fill_between(range(len(arima_pred)), arima_conf_int[:, 0], arima_conf_int[:, 1], \n",
    "                     color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.plot(lr_pred_inv, label='Linear Regression Predictions', color='orange')\n",
    "    plt.plot(gbr_pred_inv, label='Gradient Boosting Predictions', color='red')\n",
    "    plt.plot(rfr_pred_inv, label='Random Forest Predictions', color='purple')\n",
    "    plt.plot(svr_pred_inv, label='SVR Predictions', color='brown')\n",
    "    plt.plot(xgb_pred_inv, label='XGBoost Predictions', color='cyan')\n",
    "    plt.title('Model Predictions vs Actual BTC Prices (LSTM Metrics Only)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('latex\\images\\combined_model_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Performance Metrics Comparison\n",
    "    models_metrics = [\n",
    "        (\"ARIMA\", arima_mae, arima_rmse, arima_r2),\n",
    "        (\"Linear Regression\", lr_mae, lr_rmse, lr_r2),\n",
    "        (\"Gradient Boosting\", gbr_mae, gbr_rmse, gbr_r2),\n",
    "        (\"Random Forest\", rfr_mae, rfr_rmse, rfr_r2),\n",
    "        (\"SVR\", svr_mae, svr_rmse, svr_r2),\n",
    "        (\"XGBoost\", xgb_mae, xgb_rmse, xgb_r2),\n",
    "        (\"LSTM\", lstm_mae, lstm_rmse, lstm_r2)\n",
    "    ]\n",
    "    plot_performance_comparison(models_metrics)\n",
    "    \n",
    "    # Statistical Tests: Paired t-tests against LSTM (using synthetic errors for LSTM)\n",
    "    lstm_synthetic_mae = np.full_like(lr_true_inv.flatten(), lstm_mae)\n",
    "    lstm_synthetic_rmse = np.full_like(lr_true_inv.flatten(), lstm_rmse)\n",
    "    \n",
    "    t_tests_mae = {}\n",
    "    t_tests_rmse = {}\n",
    "    for name, pred, true in [\n",
    "        (\"ARIMA\", arima_pred, scaler.inverse_transform(test_targets)),\n",
    "        (\"Linear Regression\", lr_pred_inv, lr_true_inv),\n",
    "        (\"Gradient Boosting\", gbr_pred_inv, gbr_true_inv),\n",
    "        (\"Random Forest\", rfr_pred_inv, rfr_true_inv),\n",
    "        (\"SVR\", svr_pred_inv, svr_true_inv),\n",
    "        (\"XGBoost\", xgb_pred_inv, xgb_true_inv)\n",
    "    ]:\n",
    "        errors_mae = np.abs(true.flatten() - pred.flatten())\n",
    "        t_stat_mae, p_val_mae = ttest_rel(errors_mae, lstm_synthetic_mae)\n",
    "        errors_rmse = (true.flatten() - pred.flatten())**2\n",
    "        lstm_synthetic_rmse_errors = lstm_synthetic_rmse**2\n",
    "        t_stat_rmse, p_val_rmse = ttest_rel(errors_rmse, lstm_synthetic_rmse_errors)\n",
    "        t_tests_mae[name] = p_val_mae\n",
    "        t_tests_rmse[name] = p_val_rmse\n",
    "    \n",
    "    # Generate Individual LaTeX Tables for Each Model\n",
    "    models = [\n",
    "        (\"ARIMA\", arima_mae, arima_rmse, arima_r2),\n",
    "        (\"linear\", lr_mae, lr_rmse, lr_r2),\n",
    "        (\"Gradient Boosting\", gbr_mae, gbr_rmse, gbr_r2),\n",
    "        (\"Random Forest\", rfr_mae, rfr_rmse, rfr_r2),\n",
    "        (\"SVR\", svr_mae, svr_rmse, svr_r2),\n",
    "        (\"XGBoost\", xgb_mae, xgb_rmse, xgb_r2),\n",
    "        (\"LSTM\", lstm_mae, lstm_rmse, lstm_r2)\n",
    "    ]\n",
    "    \n",
    "    for model_name, mae, rmse, r2 in models:\n",
    "        latex_table = f\"\"\"\n",
    "        \\\\begin{{table}}[h]\n",
    "            \\\\centering\n",
    "            \\\\begin{{tabular}}{{cccc}}\n",
    "                \\\\toprule\n",
    "                \\\\textbf{{مدل}} & \\\\textbf{{MAE}} & \\\\textbf{{RMSE}} & \\\\textbf{{ \\\\(R^2\\\\) }} \\\\\\\\\n",
    "                \\\\midrule\n",
    "                {model_name} & {mae:.4f} & {rmse:.4f} & {r2:.4f} \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "            \\\\caption{{عملکرد مدل {model_name} در پیش‌بینی قیمت بیت‌کوین}}\n",
    "            \\\\label{{tab:{model_name.lower().replace(\" \", \"_\")}_performance}}\n",
    "        \\\\end{{table}}\n",
    "        \"\"\"\n",
    "        with open(rf'latex\\chapters\\{model_name.lower().replace(\" \", \"_\")}_performance_table.tex', 'w', encoding='utf-8') as f:\n",
    "            f.write(latex_table)\n",
    "    \n",
    "    # Generate Combined Comparison Table with P-values\n",
    "    latex_comparison_table = f\"\"\"\n",
    "    \\\\begin{{table}}[h]\n",
    "        \\\\centering\n",
    "        \\\\begin{{tabular}}{{cccccc}}\n",
    "            \\\\toprule\n",
    "            \\\\textbf{{مدل}} & \\\\textbf{{MAE}} & \\\\textbf{{p-value (MAE)}} & \\\\textbf{{RMSE}} & \\\\textbf{{p-value (RMSE)}} & \\\\textbf{{ \\\\(R^2\\\\) }} \\\\\\\\\n",
    "            \\\\midrule\n",
    "            ARIMA & {arima_mae:.4f} & {t_tests_mae['ARIMA']:.4f} & {arima_rmse:.4f} & {t_tests_rmse['ARIMA']:.4f} & {arima_r2:.4f} \\\\\\\\\n",
    "            رگرسیون خطی & {lr_mae:.4f} & {t_tests_mae['Linear Regression']:.4f} & {lr_rmse:.4f} & {t_tests_rmse['Linear Regression']:.4f} & {lr_r2:.4f} \\\\\\\\\n",
    "            Gradient Boosting & {gbr_mae:.4f} & {t_tests_mae['Gradient Boosting']:.4f} & {gbr_rmse:.4f} & {t_tests_rmse['Gradient Boosting']:.4f} & {gbr_r2:.4f} \\\\\\\\\n",
    "            Random Forest & {rfr_mae:.4f} & {t_tests_mae['Random Forest']:.4f} & {rfr_rmse:.4f} & {t_tests_rmse['Random Forest']:.4f} & {rfr_r2:.4f} \\\\\\\\\n",
    "            SVR & {svr_mae:.4f} & {t_tests_mae['SVR']:.4f} & {svr_rmse:.4f} & {t_tests_rmse['SVR']:.4f} & {svr_r2:.4f} \\\\\\\\\n",
    "            XGBoost & {xgb_mae:.4f} & {t_tests_mae['XGBoost']:.4f} & {xgb_rmse:.4f} & {t_tests_rmse['XGBoost']:.4f} & {xgb_r2:.4f} \\\\\\\\\n",
    "            مدل پیشنهادی (LSTM) & {lstm_mae:.4f} & -- & {lstm_rmse:.4f} & -- & {lstm_r2:.4f} \\\\\\\\\n",
    "            \\\\bottomrule\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\caption{{مقایسه عملکرد مدل‌های مختلف در پیش‌بینی قیمت بیت‌کوین با آزمون t جفت‌شده نسبت به LSTM}}\n",
    "        \\\\label{{tab:model_comparison}}\n",
    "    \\\\end{{table}}\n",
    "    \"\"\"\n",
    "    with open(r'latex\\chapters\\model_comparison_table.tex', 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_comparison_table)\n",
    "\n",
    "    # Generate Feature Importance Table for Tree-Based Models\n",
    "    feature_names = [f'Lag {i+1}' for i in range(7)] + ['MA7']\n",
    "    latex_feature_importance = f\"\"\"\n",
    "    \\\\begin{{table}}[h]\n",
    "        \\\\centering\n",
    "        \\\\begin{{tabular}}{{lccc}}\n",
    "            \\\\toprule\n",
    "            \\\\textbf{{ویژگی}} & \\\\textbf{{Gradient Boosting}} & \\\\textbf{{Random Forest}} & \\\\textbf{{XGBoost}} \\\\\\\\\n",
    "            \\\\midrule\n",
    "    \"\"\"\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        latex_feature_importance += f\"        {fname} & {gbr_model.feature_importances_[i]:.4f} & {rfr_model.feature_importances_[i]:.4f} & {xgb_model.feature_importances_[i]:.4f} \\\\\\\\\\n\"\n",
    "    latex_feature_importance += f\"\"\"\n",
    "            \\\\bottomrule\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\caption{{اهمیت ویژگی‌ها در مدل‌های مبتنی بر درخت (Gradient Boosting، Random Forest، XGBoost)}}\n",
    "        \\\\label{{tab:feature_importance}}\n",
    "    \\\\end{{table}}\n",
    "    \"\"\"\n",
    "    with open(r'latex\\chapters\\feature_importance_table.tex', 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd1dfddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-14091.988, Time=2.86 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-14096.215, Time=0.48 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-14096.271, Time=0.56 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-14096.218, Time=0.67 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-14097.829, Time=0.21 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-14094.333, Time=1.06 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 5.847 seconds\n",
      "\n",
      "Model Performance Comparison:\n",
      "ARIMA - MAE: 22068.6384, RMSE: 26600.0228, R2: -2.1119\n",
      "Linear Regression - MAE: 1303.4137, RMSE: 1832.4142, R2: 0.9852\n",
      "Gradient Boosting - MAE: 6098.2405, RMSE: 11970.7240, R2: 0.3698\n",
      "Random Forest - MAE: 6504.4641, RMSE: 12464.2005, R2: 0.3167\n",
      "SVR - MAE: 14635.8548, RMSE: 23734.6798, R2: -1.4776\n",
      "XGBoost - MAE: 6956.9256, RMSE: 12993.2411, R2: 0.2575\n",
      "LSTM - MAE: 0.0120, RMSE: 0.0200, R2: 0.8800\n"
     ]
    }
   ],
   "source": [
    "additional_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b9ad4",
   "metadata": {},
   "source": [
    "<h1>Adding Block Chain Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3d05eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def fetch_btc_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    try:\n",
    "        # Convert dates to Unix timestamps for CoinGecko API\n",
    "        start_ts = int(pd.Timestamp(start_date).timestamp())\n",
    "        end_ts = int(pd.Timestamp(end_date).timestamp())\n",
    "        url = f\"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart/range?vs_currency=usd&from={start_ts}&to={end_ts}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching BTC data from CoinGecko: Status code {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        data = response.json()\n",
    "        prices = pd.DataFrame(data['prices'], columns=['timestamp', 'price'])\n",
    "        prices['date'] = pd.to_datetime(prices['timestamp'], unit='ms')\n",
    "        btc_data = prices.set_index('date')[['price']].rename(columns={'price': 'Close'})\n",
    "        if btc_data.empty:\n",
    "            raise ValueError(\"No data fetched from CoinGecko\")\n",
    "        return btc_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching BTC data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 2. Fetch Blockchain Data using Blockchair and CoinGecko\n",
    "def fetch_blockchain_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    try:\n",
    "        # Fetch BTC price data\n",
    "        btc_data = fetch_btc_data(start_date, end_date)\n",
    "        if btc_data.empty:\n",
    "            print(\"No valid BTC price data available\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Fetch transaction count from Blockchair (free API for basic stats)\n",
    "        start_ts = int(pd.Timestamp(start_date).timestamp())\n",
    "        end_ts = int(pd.Timestamp(end_date).timestamp())\n",
    "        tx_url = f\"https://api.blockchair.com/bitcoin/stats\"\n",
    "        tx_response = requests.get(tx_url)\n",
    "        if tx_response.status_code != 200:\n",
    "            print(f\"Error fetching transaction data: Status code {tx_response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        tx_data = tx_response.json()\n",
    "        tx_count = tx_data['data'][0]['transactions']\n",
    "        # For simplicity, assume a daily average transaction count (adjust with historical API if needed)\n",
    "        dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        tx_df = pd.DataFrame(index=dates, data={'TxCount': tx_count / len(dates)})\n",
    "\n",
    "        # Fetch trade volume (approximated via BTC price and transaction value from Blockchair)\n",
    "        vol_url = f\"https://api.blockchair.com/bitcoin/stats\"\n",
    "        vol_response = requests.get(vol_url)\n",
    "        if vol_response.status_code != 200:\n",
    "            print(f\"Error fetching volume data: Status code {vol_response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        vol_data = vol_response.json()\n",
    "        market_cap = vol_data['data'][0]['market_price_usd'] * (tx_count / len(dates))  # Rough estimate\n",
    "        vol_df = pd.DataFrame(index=dates, data={'TxVolumeBTC': market_cap / btc_data['Close'].mean()})\n",
    "\n",
    "        # Merge blockchain data\n",
    "        blockchain_data = pd.merge(tx_df[['TxCount']], vol_df[['TxVolumeBTC']], left_index=True, right_index=True, how='outer')\n",
    "        blockchain_data = blockchain_data.resample('D').mean().interpolate()\n",
    "\n",
    "        # Join with BTC price data\n",
    "        blockchain_data = blockchain_data.join(btc_data[['Close']], how='left')\n",
    "\n",
    "        # Debug: Verify structure\n",
    "        print(\"Blockchain Data index levels:\", blockchain_data.index.nlevels)\n",
    "        print(\"Blockchain Data columns after join:\", blockchain_data.columns.tolist())\n",
    "        if 'Close' not in blockchain_data.columns:\n",
    "            print(\"Join failed to include 'Close' column. Data:\", blockchain_data.head())\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Calculate TxVolumeUSD\n",
    "        blockchain_data['TxVolumeUSD'] = blockchain_data['TxVolumeBTC'] * blockchain_data['Close']\n",
    "        blockchain_data['BlockHeight'] = np.arange(500000, 500000 + len(blockchain_data))  # Approximate block height\n",
    "\n",
    "        return blockchain_data[['BlockHeight', 'TxCount', 'TxVolumeUSD']]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fetch_blockchain_data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 3. Preprocess Data with Blockchain Features\n",
    "def preprocess_data_with_blockchain(btc_data, blockchain_data):\n",
    "    if btc_data.empty or blockchain_data.empty:\n",
    "        print(\"Empty data provided to preprocess_data_with_blockchain\")\n",
    "        return (None,) * 12\n",
    "    btc_data = btc_data.fillna(method='ffill')\n",
    "    blockchain_data = blockchain_data.reindex(btc_data.index, method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    prices = btc_data['Close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Extract blockchain features\n",
    "    block_height = blockchain_data['BlockHeight'].values\n",
    "    tx_count = blockchain_data['TxCount'].values\n",
    "    tx_volume_usd = blockchain_data['TxVolumeUSD'].values\n",
    "    \n",
    "    # Combine Features\n",
    "    features = []\n",
    "    targets = prices_scaled[7:]\n",
    "    for i in range(len(prices_scaled) - 7):\n",
    "        lagged = prices_scaled[i:i+7].flatten()\n",
    "        ma7 = np.mean(prices_scaled[i:i+7])\n",
    "        blockchain_features = [block_height[i+7], tx_count[i+7], tx_volume_usd[i+7]]\n",
    "        features.append(np.append(np.append(lagged, ma7), blockchain_features))\n",
    "    features = np.array(features)\n",
    "    \n",
    "    total_samples = len(features)\n",
    "    train_size = int(total_samples * 0.7)\n",
    "    val_size = int(total_samples * 0.15)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "    \n",
    "    train_features = features[:train_size]\n",
    "    val_features = features[train_size:train_size + val_size]\n",
    "    test_features = features[train_size + val_size:]\n",
    "    train_targets = targets[:train_size]\n",
    "    val_targets = targets[train_size:train_size + val_size]\n",
    "    test_targets = targets[train_size + val_size:]\n",
    "    \n",
    "    return (train_features, val_features, test_features, \n",
    "            train_targets, val_targets, test_targets, \n",
    "            scaler, prices, btc_data, block_height, tx_count, tx_volume_usd)\n",
    "\n",
    "# 4. Volatility Analysis with GARCH(1,1)\n",
    "def volatility_analysis(data, test_size):\n",
    "    if data.empty or 'Close' not in data.columns:\n",
    "        print(\"No valid data for volatility analysis\")\n",
    "        return pd.Series(), pd.Series()\n",
    "    returns = data['Close'].pct_change().dropna() * 100\n",
    "    test_returns = returns[-test_size:]\n",
    "    train_returns = returns[:-test_size]\n",
    "    garch_model = arch_model(train_returns, vol='Garch', p=1, q=1, mean='Zero', dist='normal')\n",
    "    garch_fit = garch_model.fit(disp='off')\n",
    "    forecast = garch_fit.forecast(horizon=len(test_returns))\n",
    "    garch_volatility = np.sqrt(forecast.variance.values[-1, :])\n",
    "    realized_volatility = test_returns.rolling(window=7).std().dropna()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(realized_volatility.index, realized_volatility, label='Realized Volatility', color='blue')\n",
    "    plt.plot(realized_volatility.index, garch_volatility[:len(realized_volatility)], label='GARCH(1,1) Volatility', color='orange')\n",
    "    plt.title('Realized vs GARCH(1,1) Volatility for BTC')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Volatility (%)')\n",
    "    plt.legend()\n",
    "    plt.savefig('volatility_analysis.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return realized_volatility, garch_volatility[:len(realized_volatility)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9be228c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching BTC data from CoinGecko: Status code 401\n",
      "No valid BTC price data available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_blockchain_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39ba3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main_block_chain():\n",
    "    # Fetch and preprocess data\n",
    "    btc_data = fetch_btc_data()\n",
    "    blockchain_data = fetch_blockchain_data()\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, prices, btc_full_data, block_height, tx_count, tx_volume_usd) = preprocess_data_with_blockchain(btc_data, blockchain_data)\n",
    "    \n",
    "    # Volatility Analysis\n",
    "    realized_volatility, garch_volatility = volatility_analysis(btc_full_data, len(test_targets))\n",
    "    \n",
    "    # ARIMA Model\n",
    "    arima_pred, arima_conf_int = train_arima_model(train_targets.flatten(), val_targets.flatten(), test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(scaler.inverse_transform(test_targets), arima_pred)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, test_features, train_targets, val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "    \n",
    "    # LSTM Model with Blockchain Data\n",
    "    lstm_pred, lstm_true = await train_lstm_model_async(train_features, val_features, test_features, train_targets, val_targets, test_targets)\n",
    "    lstm_pred_inv = scaler.inverse_transform(lstm_pred)\n",
    "    lstm_true_inv = scaler.inverse_transform(lstm_true.reshape(-1, 1))\n",
    "    lstm_mae, lstm_rmse, lstm_r2 = evaluate_model(lstm_true_inv, lstm_pred_inv)\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"LSTM (with Blockchain Data) - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot Predictions\n",
    "    plot_individual_model(lr_true_inv, arima_pred, \"ARIMA\", arima_conf_int)\n",
    "    plot_individual_model(lr_true_inv, lr_pred_inv, \"LinearRegression\")\n",
    "    plot_individual_model(lstm_true_inv, lstm_pred_inv, \"LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "22829834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price              Close          High           Low          Open  \\\n",
      "Ticker           BTC-USD       BTC-USD       BTC-USD       BTC-USD   \n",
      "Date                                                                 \n",
      "2018-01-01  13657.200195  14112.200195  13154.700195  14112.200195   \n",
      "2018-01-02  14982.099609  15444.599609  13163.599609  13625.000000   \n",
      "2018-01-03  15201.000000  15572.799805  14844.500000  14978.200195   \n",
      "2018-01-04  15599.200195  15739.700195  14522.200195  15270.700195   \n",
      "2018-01-05  17429.500000  17705.199219  15202.799805  15477.200195   \n",
      "...                  ...           ...           ...           ...   \n",
      "2024-12-26  95795.515625  99884.570312  95137.882812  99297.695312   \n",
      "2024-12-27  94164.859375  97294.843750  93310.742188  95704.976562   \n",
      "2024-12-28  95163.929688  95525.898438  94014.289062  94160.187500   \n",
      "2024-12-29  93530.226562  95174.875000  92881.789062  95174.054688   \n",
      "2024-12-30  92643.210938  94903.320312  91317.132812  93527.195312   \n",
      "\n",
      "Price            Volume  \n",
      "Ticker          BTC-USD  \n",
      "Date                     \n",
      "2018-01-01  10291200000  \n",
      "2018-01-02  16846600192  \n",
      "2018-01-03  16871900160  \n",
      "2018-01-04  21783199744  \n",
      "2018-01-05  23840899072  \n",
      "...                 ...  \n",
      "2024-12-26  47054980873  \n",
      "2024-12-27  52419934565  \n",
      "2024-12-28  24107436185  \n",
      "2024-12-29  29635885267  \n",
      "2024-12-30  56188003691  \n",
      "\n",
      "[2556 rows x 5 columns]\n",
      "2018-01-01 , 2024-12-31 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mahdi\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main_block_chain()\n",
      "Cell \u001b[1;32mIn[126], line 4\u001b[0m, in \u001b[0;36mmain_block_chain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain_block_chain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Fetch and preprocess data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     btc_data \u001b[38;5;241m=\u001b[39m fetch_btc_data()\n\u001b[1;32m----> 4\u001b[0m     blockchain_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_blockchain_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     (train_features, val_features, test_features,\n\u001b[0;32m      6\u001b[0m      train_targets, val_targets, test_targets,\n\u001b[0;32m      7\u001b[0m      scaler, prices, btc_full_data, block_height, tx_count, tx_volume_usd) \u001b[38;5;241m=\u001b[39m preprocess_data_with_blockchain(btc_data, blockchain_data)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Volatility Analysis\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[153], line 39\u001b[0m, in \u001b[0;36mfetch_blockchain_data\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m     37\u001b[0m btc_price \u001b[38;5;241m=\u001b[39m btc_price[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m blockchain_data \u001b[38;5;241m=\u001b[39m blockchain_data\u001b[38;5;241m.\u001b[39mjoin(btc_price)\n\u001b[1;32m---> 39\u001b[0m blockchain_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTxVolumeUSD\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m blockchain_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTxVolumeBTC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[43mblockchain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     40\u001b[0m blockchain_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlockHeight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m500000\u001b[39m, \u001b[38;5;241m500000\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(blockchain_data))  \u001b[38;5;66;03m# Approximate block height\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blockchain_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlockHeight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTxCount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTxVolumeUSD\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\mahdi\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mahdi\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'"
     ]
    }
   ],
   "source": [
    "await main_block_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea634d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
