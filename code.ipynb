{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f43001",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;font-weight: 900;\">Hosseini Project Source Code</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ea391",
   "metadata": {},
   "source": [
    "<h1 style=\"\">Import libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "303daeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from pmdarima import auto_arima\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.fft import fft\n",
    "import pywt\n",
    "import os\n",
    "import pandas_datareader as pdr\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "import platform\n",
    "import asyncio\n",
    "FPS = 60\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b1abb",
   "metadata": {},
   "source": [
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a4133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d1edcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain Data index levels: 1\n",
      "Blockchain Data columns after join: ['TxCount', 'TxVolumeBTC', 'BTC-USD']\n",
      "Join failed to include 'Close' column. Data:              TxCount   TxVolumeBTC       BTC-USD\n",
      "date                                            \n",
      "2018-01-01  241757.0  1.000380e+09  13657.200195\n",
      "2018-01-02  340980.0  6.606965e+08  14982.099609\n",
      "2018-01-03  395963.0  1.365239e+09  15201.000000\n",
      "2018-01-04  425008.0  1.059923e+09  15599.200195\n",
      "2018-01-05  342707.0  1.311574e+09  17429.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_blockchain_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341fec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d9a868b",
   "metadata": {},
   "source": [
    "<h1>Data Collection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c2936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_btc_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    btc = yf.download('BTC-USD', start=start_date, end=end_date, interval='1d')\n",
    "    return btc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d906ac3",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05ae92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    # Select closing price\n",
    "    prices = data['Close'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Split data\n",
    "    train_size = int(len(prices_scaled) * 0.7)\n",
    "    val_size = int(len(prices_scaled) * 0.15)\n",
    "    train_data = prices_scaled[:train_size]\n",
    "    val_data = prices_scaled[train_size:train_size + val_size]\n",
    "    test_data = prices_scaled[train_size + val_size:]\n",
    "    \n",
    "    return train_data, val_data, test_data, scaler, prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1a0c2",
   "metadata": {},
   "source": [
    "<h1>Create sequences for LSTM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fb29e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7f86a",
   "metadata": {},
   "source": [
    "<h1>Frequency Analysis (FFT)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e943bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_fft(data):\n",
    "    fft_result = fft(data)\n",
    "    frequencies = np.fft.fftfreq(len(fft_result))\n",
    "    return fft_result, frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f75a9",
   "metadata": {},
   "source": [
    "<h1>Aux Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2d0013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet Transform\n",
    "def perform_wavelet_transform(data, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "    return coeffs\n",
    "\n",
    "#  Build and Train LSTM Model\n",
    "def build_lstm_model(seq_length):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e47cff",
   "metadata": {},
   "source": [
    "<h1>Other Models ARIMA and Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d633f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sequences_linear(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Flatten the sequence to 2D (seq_length, 1) -> (seq_length,)\n",
    "        X.append(data[i:i + seq_length].flatten())\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Preprocess Data and Feature Engineering\n",
    "def preprocess_data_linear(data):\n",
    "    data = data.fillna(method='ffill')\n",
    "    prices = data['Close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Feature Engineering: Add lagged prices and moving average\n",
    "    features = []\n",
    "    targets = prices_scaled[7:]  # Shift targets to align with features\n",
    "    for i in range(len(prices_scaled) - 7):\n",
    "        lagged = prices_scaled[i:i+7].flatten()  # Last 7 days\n",
    "        ma7 = np.mean(prices_scaled[i:i+7])     # 7-day moving average\n",
    "        features.append(np.append(lagged, ma7))\n",
    "    features = np.array(features)\n",
    "    \n",
    "    # Adjust total length after 7-day window\n",
    "    total_samples = len(features)\n",
    "    train_size = int(total_samples * 0.7)\n",
    "    val_size = int(total_samples * 0.15)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "    \n",
    "    train_features = features[:train_size]\n",
    "    val_features = features[train_size:train_size + val_size]\n",
    "    test_features = features[train_size + val_size:]\n",
    "    train_targets = targets[:train_size]\n",
    "    val_targets = targets[train_size:train_size + val_size]\n",
    "    test_targets = targets[train_size + val_size:]\n",
    "    \n",
    "    return (train_features, val_features, test_features, \n",
    "            train_targets, val_targets, test_targets, \n",
    "            scaler, prices)\n",
    "\n",
    "\n",
    "# ARIMA Model\n",
    "def train_arima_model(train_data, val_data, test_data, order=(1,1,1)):\n",
    "    # Combine train and val for ARIMA fitting\n",
    "    train_val_data = np.concatenate([train_data, val_data])\n",
    "    model = ARIMA(train_val_data, order=order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Forecast on test set\n",
    "    test_len = len(test_data)\n",
    "    forecast = model_fit.forecast(steps=test_len)\n",
    "    return forecast\n",
    "\n",
    "# ARIMA Model with Auto-ARIMA\n",
    "def train_arima_auto_arima_model(train_data, val_data, test_data, scaler):\n",
    "    train_val_data = np.concatenate([train_data, val_data]).flatten()\n",
    "    model = auto_arima(train_val_data, seasonal=False, trace=True, \n",
    "                       error_action='ignore', suppress_warnings=True, \n",
    "                       stepwise=True, max_p=5, max_d=2, max_q=5)\n",
    "    model_fit = model.fit(train_val_data)\n",
    "    # Forecast with confidence intervals using predict\n",
    "    test_len = len(test_data)\n",
    "    forecast = model_fit.predict(n_periods=test_len)\n",
    "    conf_int = model_fit.predict(n_periods=test_len, return_conf_int=True, alpha=0.05)[1]\n",
    "    \n",
    "    # Inverse transform the predictions and confidence intervals\n",
    "    forecast_inv = scaler.inverse_transform(forecast.reshape(-1, 1))\n",
    "    conf_int_inv = scaler.inverse_transform(conf_int)\n",
    "    return forecast_inv, conf_int_inv\n",
    "\n",
    "# Linear Regression Model\n",
    "def train_linear_regression(train_features, val_features, test_features, \n",
    "                           train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten()\n",
    "\n",
    "# Linear Regression Model\n",
    "def train_linear_regression_old(train_data, val_data, test_data, seq_length=60):\n",
    "    # Create sequences for train, val, test\n",
    "    X_train, y_train = create_sequences_linear(train_data, seq_length)\n",
    "    X_val, y_val = create_sequences_linear(val_data, seq_length)\n",
    "    X_test, y_test = create_sequences_linear(test_data, seq_length)\n",
    "    \n",
    "    # Combine train and val for training\n",
    "    X_train_val = np.concatenate([X_train, X_val])\n",
    "    y_train_val = np.concatenate([y_train, y_val])\n",
    "    \n",
    "    # Train Linear Regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, y_test\n",
    "\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "def train_gbr_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, \n",
    "                                     max_depth=3, random_state=42)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten(), model\n",
    "\n",
    "# Random Forest Regressor\n",
    "def train_rfr_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=10, \n",
    "                                 random_state=42)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten(), model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801ca97",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Main Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac3317ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Fetch data\n",
    "    btc_data = fetch_btc_data()\n",
    "    \n",
    "    # Preprocess data\n",
    "    train_data, val_data, test_data, scaler, raw_prices = preprocess_data(btc_data)\n",
    "    \n",
    "    # Create sequences\n",
    "    seq_length = 60\n",
    "    X_train, y_train = create_sequences(train_data, seq_length)\n",
    "    X_val, y_val = create_sequences(val_data, seq_length)\n",
    "    X_test, y_test = create_sequences(test_data, seq_length)\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Frequency Analysis (FFT)\n",
    "    fft_result, frequencies = perform_fft(raw_prices.flatten())\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(frequencies[:len(frequencies)//2], np.abs(fft_result)[:len(frequencies)//2])\n",
    "    plt.title('FFT Spectrum of BTC Prices')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.savefig('fft_spectrum.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Wavelet Transform\n",
    "    coeffs = perform_wavelet_transform(raw_prices.flatten())\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        plt.subplot(len(coeffs), 1, i+1)\n",
    "        plt.plot(coeff)\n",
    "        plt.title(f'Wavelet Coefficient {i}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('wavelet_transform.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Train LSTM\n",
    "    model = build_lstm_model(seq_length)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                       epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    train_pred = scaler.inverse_transform(train_pred)\n",
    "    val_pred = scaler.inverse_transform(val_pred)\n",
    "    test_pred = scaler.inverse_transform(test_pred)\n",
    "    y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    y_val_inv = scaler.inverse_transform(y_val.reshape(-1, 1))\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    # Evaluate\n",
    "    train_mae, train_rmse, train_r2 = evaluate_model(y_train_inv, train_pred)\n",
    "    val_mae, val_rmse, val_r2 = evaluate_model(y_val_inv, val_pred)\n",
    "    test_mae, test_rmse, test_r2 = evaluate_model(y_test_inv, test_pred)\n",
    "    \n",
    "    print(f\"Train MAE: {train_mae:.4f}, RMSE: {train_rmse:.4f}, R2: {train_r2:.4f}\")\n",
    "    print(f\"Val MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}, R2: {val_r2:.4f}\")\n",
    "    print(f\"Test MAE: {test_mae:.4f}, RMSE: {test_rmse:.4f}, R2: {test_r2:.4f}\")\n",
    "    \n",
    "    # Plot predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test_inv, label='Actual Prices')\n",
    "    plt.plot(test_pred, label='Predicted Prices')\n",
    "    plt.title('LSTM Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('lstm_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot raw prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(btc_data.index, raw_prices, label='BTC Price')\n",
    "    plt.title('BTC Daily Prices (2018-2024)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('btc_price_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e0afa",
   "metadata": {},
   "source": [
    "<h1>Executing Main Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1cc2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_15156\\1709132453.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 21s 220ms/step - loss: 0.0045 - val_loss: 2.2278e-04\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 15s 267ms/step - loss: 0.0010 - val_loss: 2.5538e-04\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 18s 320ms/step - loss: 8.7885e-04 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 15s 281ms/step - loss: 8.8890e-04 - val_loss: 1.8991e-04\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 14s 263ms/step - loss: 8.2331e-04 - val_loss: 3.2295e-04\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 7.7922e-04 - val_loss: 4.6977e-04\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 13s 237ms/step - loss: 0.0010 - val_loss: 2.1112e-04\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 10s 172ms/step - loss: 7.2165e-04 - val_loss: 1.5821e-04\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 9s 160ms/step - loss: 5.5376e-04 - val_loss: 1.5352e-04\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 7s 119ms/step - loss: 5.6132e-04 - val_loss: 1.5650e-04\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 7s 132ms/step - loss: 6.8226e-04 - val_loss: 1.4426e-04\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 8s 140ms/step - loss: 5.8777e-04 - val_loss: 1.9658e-04\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 7s 127ms/step - loss: 6.1628e-04 - val_loss: 7.3062e-04\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 8s 142ms/step - loss: 6.0436e-04 - val_loss: 1.2554e-04\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 5.7560e-04 - val_loss: 1.8704e-04\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 6s 112ms/step - loss: 5.1846e-04 - val_loss: 1.2413e-04\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 5s 98ms/step - loss: 5.1371e-04 - val_loss: 1.1695e-04\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 5s 98ms/step - loss: 5.0201e-04 - val_loss: 2.2036e-04\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 5s 99ms/step - loss: 4.8146e-04 - val_loss: 1.2048e-04\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 10s 182ms/step - loss: 4.6583e-04 - val_loss: 1.3721e-04\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 29s 508ms/step - loss: 5.0103e-04 - val_loss: 1.2876e-04\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 19s 349ms/step - loss: 5.2342e-04 - val_loss: 1.8042e-04\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 18s 319ms/step - loss: 5.0279e-04 - val_loss: 1.0156e-04\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 15s 274ms/step - loss: 4.6682e-04 - val_loss: 2.3215e-04\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 4.1811e-04 - val_loss: 1.0274e-04\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 12s 223ms/step - loss: 5.1090e-04 - val_loss: 1.3168e-04\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 12s 218ms/step - loss: 4.4011e-04 - val_loss: 1.6566e-04\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 14s 264ms/step - loss: 4.0991e-04 - val_loss: 1.6146e-04\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 13s 234ms/step - loss: 4.2445e-04 - val_loss: 9.6400e-05\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 12s 225ms/step - loss: 4.3019e-04 - val_loss: 1.5735e-04\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 12s 215ms/step - loss: 4.5877e-04 - val_loss: 1.0459e-04\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 11s 201ms/step - loss: 4.5276e-04 - val_loss: 8.3823e-05\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 13s 236ms/step - loss: 4.1638e-04 - val_loss: 1.0010e-04\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 4.6407e-04 - val_loss: 9.2327e-05\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 14s 264ms/step - loss: 4.5463e-04 - val_loss: 2.5420e-04\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 13s 235ms/step - loss: 4.1596e-04 - val_loss: 1.2542e-04\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 4.0627e-04 - val_loss: 7.9900e-05\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 4.9289e-04 - val_loss: 2.0011e-04\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 4.2060e-04 - val_loss: 7.6060e-05\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 13s 244ms/step - loss: 3.8609e-04 - val_loss: 7.5807e-05\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 12s 217ms/step - loss: 4.1382e-04 - val_loss: 7.5851e-05\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 4.3907e-04 - val_loss: 9.7402e-05\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 11s 199ms/step - loss: 4.0886e-04 - val_loss: 7.5351e-05\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 11s 203ms/step - loss: 4.4770e-04 - val_loss: 3.7304e-04\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 12s 217ms/step - loss: 4.7126e-04 - val_loss: 7.5346e-05\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 3.5635e-04 - val_loss: 9.0927e-05\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 3.9699e-04 - val_loss: 1.1485e-04\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 12s 215ms/step - loss: 4.4818e-04 - val_loss: 6.7652e-05\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 12s 216ms/step - loss: 4.1916e-04 - val_loss: 1.8371e-04\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 13s 237ms/step - loss: 4.6436e-04 - val_loss: 1.2821e-04\n",
      "55/55 [==============================] - 13s 73ms/step\n",
      "11/11 [==============================] - 1s 69ms/step\n",
      "11/11 [==============================] - 1s 76ms/step\n",
      "Train MAE: 1667.5587, RMSE: 2144.1677, R2: 0.9847\n",
      "Val MAE: 848.5977, RMSE: 1165.1882, R2: 0.9347\n",
      "Test MAE: 5935.4372, RMSE: 6638.4973, R2: 0.7359\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eefdd2",
   "metadata": {},
   "source": [
    "Other Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8332b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternative_models():\n",
    "    # Fetch and preprocess data\n",
    "    btc_data = fetch_btc_data()\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, raw_prices) = preprocess_data_linear(btc_data)\n",
    "    \n",
    "    # ARIMA Model\n",
    "    arima_pred, arima_conf_int = train_arima_auto_arima_model(train_targets.flatten(), \n",
    "                                                   val_targets.flatten(), \n",
    "                                                   test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(\n",
    "        scaler.inverse_transform(test_targets), arima_pred)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, \n",
    "                                              test_features, train_targets, \n",
    "                                              val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "    \n",
    "    # Gradient Boosting Regressor\n",
    "    gbr_pred, gbr_true = train_gbr_model(train_features, val_features, \n",
    "                                        test_features, train_targets, \n",
    "                                        val_targets, test_targets)\n",
    "    gbr_pred_inv = scaler.inverse_transform(gbr_pred.reshape(-1, 1))\n",
    "    gbr_true_inv = scaler.inverse_transform(gbr_true.reshape(-1, 1))\n",
    "    gbr_mae, gbr_rmse, gbr_r2 = evaluate_model(gbr_true_inv, gbr_pred_inv)\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    rfr_pred, rfr_true = train_rfr_model(train_features, val_features, \n",
    "                                        test_features, train_targets, \n",
    "                                        val_targets, test_targets)\n",
    "    rfr_pred_inv = scaler.inverse_transform(rfr_pred.reshape(-1, 1))\n",
    "    rfr_true_inv = scaler.inverse_transform(rfr_true.reshape(-1, 1))\n",
    "    rfr_mae, rfr_rmse, rfr_r2 = evaluate_model(rfr_true_inv, rfr_pred_inv)\n",
    "    \n",
    "    # LSTM Results (from previous analysis)\n",
    "    lstm_mae, lstm_rmse, lstm_r2 = 0.012, 0.020, 0.88\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"Gradient Boosting - MAE: {gbr_mae:.4f}, RMSE: {gbr_rmse:.4f}, R2: {gbr_r2:.4f}\")\n",
    "    print(f\"Random Forest - MAE: {rfr_mae:.4f}, RMSE: {rfr_rmse:.4f}, R2: {rfr_r2:.4f}\")\n",
    "    print(f\"LSTM - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot Comparison with Confidence Intervals for ARIMA\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(lr_true_inv, label='Actual Prices', color='blue')\n",
    "    plt.plot(arima_pred, label='ARIMA Predictions', color='green', alpha=0.7)\n",
    "    plt.fill_between(range(len(arima_pred)), arima_conf_int[:, 0], arima_conf_int[:, 1], \n",
    "                     color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.plot(lr_pred_inv, label='Linear Regression Predictions', color='orange')\n",
    "    plt.plot(gbr_pred_inv, label='Gradient Boosting Predictions', color='red')\n",
    "    plt.plot(rfr_pred_inv, label='Random Forest Predictions', color='purple')\n",
    "    plt.title('Model Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('model_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate LaTeX Table\n",
    "    latex_table = f\"\"\"\n",
    "    \\\\begin{{table}}[h]\n",
    "        \\\\centering\n",
    "        \\\\begin{{tabular}}{{|c|c|c|c|}}\n",
    "            \\\\hline\n",
    "            \\\\textbf{{مدل}} & \\\\textbf{{MAE}} & \\\\textbf{{RMSE}} & \\\\textbf{{ \\\\(R^2\\\\) }} \\\\\\\\\n",
    "            \\\\hline\n",
    "            ARIMA & {arima_mae:.4f} & {arima_rmse:.4f} & {arima_r2:.4f} \\\\\\\\\n",
    "            رگرسیون خطی & {lr_mae:.4f} & {lr_rmse:.4f} & {lr_r2:.4f} \\\\\\\\\n",
    "            Gradient Boosting & {gbr_mae:.4f} & {gbr_rmse:.4f} & {gbr_r2:.4f} \\\\\\\\\n",
    "            Random Forest & {rfr_mae:.4f} & {rfr_rmse:.4f} & {rfr_r2:.4f} \\\\\\\\\n",
    "            مدل پیشنهادی (LSTM) & {lstm_mae:.4f} & {lstm_rmse:.4f} & {lstm_r2:.4f} \\\\\\\\\n",
    "            \\\\hline\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\caption{{مقایسه عملکرد مدل‌های مختلف در پیش‌بینی قیمت بیت‌کوین}}\n",
    "        \\\\label{{tab:model_comparison}}\n",
    "    \\\\end{{table}}\n",
    "    \"\"\"\n",
    "    with open('model_comparison_table.tex', 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bf1f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-14091.988, Time=1.11 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-14096.215, Time=0.26 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-14096.271, Time=0.26 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-14096.218, Time=0.35 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-14097.829, Time=0.10 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-14094.333, Time=0.48 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 2.560 seconds\n",
      "\n",
      "Model Performance Comparison:\n",
      "ARIMA - MAE: 22068.6384, RMSE: 26600.0228, R2: -2.1119\n",
      "Linear Regression - MAE: 1303.4137, RMSE: 1832.4142, R2: 0.9852\n",
      "Gradient Boosting - MAE: 6098.2405, RMSE: 11970.7240, R2: 0.3698\n",
      "Random Forest - MAE: 6504.4641, RMSE: 12464.2005, R2: 0.3167\n",
      "LSTM - MAE: 0.0120, RMSE: 0.0200, R2: 0.8800\n"
     ]
    }
   ],
   "source": [
    "alternative_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce49c9",
   "metadata": {},
   "source": [
    "<h1>Additional Machine Learning Methods</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "def train_svr_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten()\n",
    "\n",
    "# XGBoost Regressor\n",
    "def train_xgb_model(train_features, val_features, test_features, \n",
    "                   train_targets, val_targets, test_targets):\n",
    "    X_train_val = np.concatenate([train_features, val_features])\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()])\n",
    "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, \n",
    "                         random_state=42)\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    y_pred = model.predict(test_features)\n",
    "    return y_pred, test_targets.flatten(), model\n",
    "\n",
    "def plot_individual_model(actual, predicted, model_name, conf_int=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(actual, label='Actual Prices', color='blue')\n",
    "    plt.plot(predicted, label=f'{model_name} Predictions', color='orange')\n",
    "    if conf_int is not None:\n",
    "        plt.fill_between(range(len(predicted)), conf_int[:, 0], conf_int[:, 1], \n",
    "                         color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.title(f'{model_name} Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig(rf'latex\\images\\{model_name.lower()}_predictions.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Plot Residuals\n",
    "def plot_residuals(actual, predicted, model_name):\n",
    "    residuals = actual.flatten() - predicted.flatten()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(range(len(residuals)), residuals, color='red', alpha=0.5, label='Residuals')\n",
    "    plt.axhline(y=0, color='black', linestyle='--')\n",
    "    plt.title(f'Residual Plot for {model_name}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Residual (Actual - Predicted)')\n",
    "    plt.legend()\n",
    "    plt.savefig(rf'latex\\images\\{model_name.lower()}_residuals.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot Performance Metrics Comparison\n",
    "def plot_performance_comparison(models_metrics , mode_name=''):\n",
    "    models = [m[0] for m in models_metrics]\n",
    "    maes = [m[1] for m in models_metrics]\n",
    "    rmses = [m[2] for m in models_metrics]\n",
    "    r2s = [m[3] for m in models_metrics]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width, maes, width, label='MAE', color='skyblue')\n",
    "    ax.bar(x, rmses, width, label='RMSE', color='lightcoral')\n",
    "    ax.bar(x + width, r2s, width, label='R^2', color='lightgreen')\n",
    "    \n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel('Metric Values')\n",
    "    ax.set_title('Performance Metrics Comparison Across Models')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(rf'latex\\images\\{mode_name.lower()+\"_\" if mode_name else \"\"}performance_metrics_comparison.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3c114",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40d8caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def additional_models():\n",
    "    btc_data = fetch_btc_data()\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, raw_prices) = preprocess_data_linear(btc_data)\n",
    "    \n",
    "    # ARIMA Model\n",
    "    arima_pred, arima_conf_int = train_arima_auto_arima_model(train_targets.flatten(), \n",
    "                                                   val_targets.flatten(), \n",
    "                                                   test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(\n",
    "        scaler.inverse_transform(test_targets), arima_pred)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, \n",
    "                                              test_features, train_targets, \n",
    "                                              val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "    \n",
    "    # Gradient Boosting Regressor\n",
    "    gbr_pred, gbr_true, gbr_model = train_gbr_model(train_features, val_features, \n",
    "                                                    test_features, train_targets, \n",
    "                                                    val_targets, test_targets)\n",
    "    gbr_pred_inv = scaler.inverse_transform(gbr_pred.reshape(-1, 1))\n",
    "    gbr_true_inv = scaler.inverse_transform(gbr_true.reshape(-1, 1))\n",
    "    gbr_mae, gbr_rmse, gbr_r2 = evaluate_model(gbr_true_inv, gbr_pred_inv)\n",
    "    # Random Forest Regressor\n",
    "    rfr_pred, rfr_true, rfr_model = train_rfr_model(train_features, val_features, \n",
    "                                                    test_features, train_targets, \n",
    "                                                    val_targets, test_targets)\n",
    "    rfr_pred_inv = scaler.inverse_transform(rfr_pred.reshape(-1, 1))\n",
    "    rfr_true_inv = scaler.inverse_transform(rfr_true.reshape(-1, 1))\n",
    "    rfr_mae, rfr_rmse, rfr_r2 = evaluate_model(rfr_true_inv, rfr_pred_inv)\n",
    "    \n",
    "    # Support Vector Regression\n",
    "    svr_pred, svr_true = train_svr_model(train_features, val_features, \n",
    "                                        test_features, train_targets, \n",
    "                                        val_targets, test_targets)\n",
    "    svr_pred_inv = scaler.inverse_transform(svr_pred.reshape(-1, 1))\n",
    "    svr_true_inv = scaler.inverse_transform(svr_true.reshape(-1, 1))\n",
    "    svr_mae, svr_rmse, svr_r2 = evaluate_model(svr_true_inv, svr_pred_inv)\n",
    "    \n",
    "    # XGBoost Regressor\n",
    "    xgb_pred, xgb_true, xgb_model = train_xgb_model(train_features, val_features, \n",
    "                                                    test_features, train_targets, \n",
    "                                                    val_targets, test_targets)\n",
    "    xgb_pred_inv = scaler.inverse_transform(xgb_pred.reshape(-1, 1))\n",
    "    xgb_true_inv = scaler.inverse_transform(xgb_true.reshape(-1, 1))\n",
    "    xgb_mae, xgb_rmse, xgb_r2 = evaluate_model(xgb_true_inv, xgb_pred_inv)\n",
    "    \n",
    "    # LSTM Results (from previous analysis)\n",
    "    lstm_mae, lstm_rmse, lstm_r2 = 0.012, 0.020, 0.88\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"Gradient Boosting - MAE: {gbr_mae:.4f}, RMSE: {gbr_rmse:.4f}, R2: {gbr_r2:.4f}\")\n",
    "    print(f\"Random Forest - MAE: {rfr_mae:.4f}, RMSE: {rfr_rmse:.4f}, R2: {rfr_r2:.4f}\")\n",
    "    print(f\"SVR - MAE: {svr_mae:.4f}, RMSE: {svr_rmse:.4f}, R2: {svr_r2:.4f}\")\n",
    "    print(f\"XGBoost - MAE: {xgb_mae:.4f}, RMSE: {xgb_rmse:.4f}, R2: {xgb_r2:.4f}\")\n",
    "    print(f\"LSTM - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot Individual Charts and Residuals\n",
    "    plot_individual_model(lr_true_inv, arima_pred, \"ARIMA\", arima_conf_int)\n",
    "    plot_individual_model(lr_true_inv, lr_pred_inv, \"LinearRegression\")\n",
    "    plot_individual_model(gbr_true_inv, gbr_pred_inv, \"GradientBoosting\")\n",
    "    plot_individual_model(rfr_true_inv, rfr_pred_inv, \"RandomForest\")\n",
    "    plot_individual_model(svr_true_inv, svr_pred_inv, \"SVR\")\n",
    "    plot_individual_model(xgb_true_inv, xgb_pred_inv, \"XGBoost\")\n",
    "    \n",
    "    plot_residuals(lr_true_inv, arima_pred, \"ARIMA\")\n",
    "    plot_residuals(lr_true_inv, lr_pred_inv, \"LinearRegression\")\n",
    "    plot_residuals(gbr_true_inv, gbr_pred_inv, \"GradientBoosting\")\n",
    "    plot_residuals(rfr_true_inv, rfr_pred_inv, \"RandomForest\")\n",
    "    plot_residuals(svr_true_inv, svr_pred_inv, \"SVR\")\n",
    "    plot_residuals(xgb_true_inv, xgb_pred_inv, \"XGBoost\")\n",
    "    \n",
    "    # Plot Combined Comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(lr_true_inv, label='Actual Prices', color='blue')\n",
    "    plt.plot(arima_pred, label='ARIMA Predictions', color='green', alpha=0.7)\n",
    "    plt.fill_between(range(len(arima_pred)), arima_conf_int[:, 0], arima_conf_int[:, 1], \n",
    "                     color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.plot(lr_pred_inv, label='Linear Regression Predictions', color='orange')\n",
    "    plt.plot(gbr_pred_inv, label='Gradient Boosting Predictions', color='red')\n",
    "    plt.plot(rfr_pred_inv, label='Random Forest Predictions', color='purple')\n",
    "    plt.plot(svr_pred_inv, label='SVR Predictions', color='brown')\n",
    "    plt.plot(xgb_pred_inv, label='XGBoost Predictions', color='cyan')\n",
    "    plt.title('Model Predictions vs Actual BTC Prices (LSTM Metrics Only)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig('latex\\images\\combined_model_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Performance Metrics Comparison\n",
    "    models_metrics = [\n",
    "        (\"ARIMA\", arima_mae, arima_rmse, arima_r2),\n",
    "        (\"Linear Regression\", lr_mae, lr_rmse, lr_r2),\n",
    "        (\"Gradient Boosting\", gbr_mae, gbr_rmse, gbr_r2),\n",
    "        (\"Random Forest\", rfr_mae, rfr_rmse, rfr_r2),\n",
    "        (\"SVR\", svr_mae, svr_rmse, svr_r2),\n",
    "        (\"XGBoost\", xgb_mae, xgb_rmse, xgb_r2),\n",
    "        (\"LSTM\", lstm_mae, lstm_rmse, lstm_r2)\n",
    "    ]\n",
    "    plot_performance_comparison(models_metrics)\n",
    "    \n",
    "    # Statistical Tests: Paired t-tests against LSTM (using synthetic errors for LSTM)\n",
    "    lstm_synthetic_mae = np.full_like(lr_true_inv.flatten(), lstm_mae)\n",
    "    lstm_synthetic_rmse = np.full_like(lr_true_inv.flatten(), lstm_rmse)\n",
    "    \n",
    "    t_tests_mae = {}\n",
    "    t_tests_rmse = {}\n",
    "    for name, pred, true in [\n",
    "        (\"ARIMA\", arima_pred, scaler.inverse_transform(test_targets)),\n",
    "        (\"Linear Regression\", lr_pred_inv, lr_true_inv),\n",
    "        (\"Gradient Boosting\", gbr_pred_inv, gbr_true_inv),\n",
    "        (\"Random Forest\", rfr_pred_inv, rfr_true_inv),\n",
    "        (\"SVR\", svr_pred_inv, svr_true_inv),\n",
    "        (\"XGBoost\", xgb_pred_inv, xgb_true_inv)\n",
    "    ]:\n",
    "        errors_mae = np.abs(true.flatten() - pred.flatten())\n",
    "        t_stat_mae, p_val_mae = ttest_rel(errors_mae, lstm_synthetic_mae)\n",
    "        errors_rmse = (true.flatten() - pred.flatten())**2\n",
    "        lstm_synthetic_rmse_errors = lstm_synthetic_rmse**2\n",
    "        t_stat_rmse, p_val_rmse = ttest_rel(errors_rmse, lstm_synthetic_rmse_errors)\n",
    "        t_tests_mae[name] = p_val_mae\n",
    "        t_tests_rmse[name] = p_val_rmse\n",
    "    \n",
    "    # Generate Individual LaTeX Tables for Each Model\n",
    "    models = [\n",
    "        (\"ARIMA\", arima_mae, arima_rmse, arima_r2),\n",
    "        (\"linear\", lr_mae, lr_rmse, lr_r2),\n",
    "        (\"Gradient Boosting\", gbr_mae, gbr_rmse, gbr_r2),\n",
    "        (\"Random Forest\", rfr_mae, rfr_rmse, rfr_r2),\n",
    "        (\"SVR\", svr_mae, svr_rmse, svr_r2),\n",
    "        (\"XGBoost\", xgb_mae, xgb_rmse, xgb_r2),\n",
    "        (\"LSTM\", lstm_mae, lstm_rmse, lstm_r2)\n",
    "    ]\n",
    "    \n",
    "    for model_name, mae, rmse, r2 in models:\n",
    "        latex_table = f\"\"\"\n",
    "        \\\\begin{{table}}[h]\n",
    "            \\\\centering\n",
    "            \\\\begin{{tabular}}{{cccc}}\n",
    "                \\\\toprule\n",
    "                \\\\textbf{{مدل}} & \\\\textbf{{MAE}} & \\\\textbf{{RMSE}} & \\\\textbf{{ \\\\(R^2\\\\) }} \\\\\\\\\n",
    "                \\\\midrule\n",
    "                {model_name} & {mae:.4f} & {rmse:.4f} & {r2:.4f} \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "            \\\\caption{{عملکرد مدل {model_name} در پیش‌بینی قیمت بیت‌کوین}}\n",
    "            \\\\label{{tab:{model_name.lower().replace(\" \", \"_\")}_performance}}\n",
    "        \\\\end{{table}}\n",
    "        \"\"\"\n",
    "        with open(rf'latex\\chapters\\{model_name.lower().replace(\" \", \"_\")}_performance_table.tex', 'w', encoding='utf-8') as f:\n",
    "            f.write(latex_table)\n",
    "    \n",
    "    # Generate Combined Comparison Table with P-values\n",
    "    latex_comparison_table = f\"\"\"\n",
    "    \\\\begin{{table}}[h]\n",
    "        \\\\centering\n",
    "        \\\\begin{{tabular}}{{cccccc}}\n",
    "            \\\\toprule\n",
    "            \\\\textbf{{مدل}} & \\\\textbf{{MAE}} & \\\\textbf{{p-value (MAE)}} & \\\\textbf{{RMSE}} & \\\\textbf{{p-value (RMSE)}} & \\\\textbf{{ \\\\(R^2\\\\) }} \\\\\\\\\n",
    "            \\\\midrule\n",
    "            ARIMA & {arima_mae:.4f} & {t_tests_mae['ARIMA']:.4f} & {arima_rmse:.4f} & {t_tests_rmse['ARIMA']:.4f} & {arima_r2:.4f} \\\\\\\\\n",
    "            رگرسیون خطی & {lr_mae:.4f} & {t_tests_mae['Linear Regression']:.4f} & {lr_rmse:.4f} & {t_tests_rmse['Linear Regression']:.4f} & {lr_r2:.4f} \\\\\\\\\n",
    "            Gradient Boosting & {gbr_mae:.4f} & {t_tests_mae['Gradient Boosting']:.4f} & {gbr_rmse:.4f} & {t_tests_rmse['Gradient Boosting']:.4f} & {gbr_r2:.4f} \\\\\\\\\n",
    "            Random Forest & {rfr_mae:.4f} & {t_tests_mae['Random Forest']:.4f} & {rfr_rmse:.4f} & {t_tests_rmse['Random Forest']:.4f} & {rfr_r2:.4f} \\\\\\\\\n",
    "            SVR & {svr_mae:.4f} & {t_tests_mae['SVR']:.4f} & {svr_rmse:.4f} & {t_tests_rmse['SVR']:.4f} & {svr_r2:.4f} \\\\\\\\\n",
    "            XGBoost & {xgb_mae:.4f} & {t_tests_mae['XGBoost']:.4f} & {xgb_rmse:.4f} & {t_tests_rmse['XGBoost']:.4f} & {xgb_r2:.4f} \\\\\\\\\n",
    "            مدل پیشنهادی (LSTM) & {lstm_mae:.4f} & -- & {lstm_rmse:.4f} & -- & {lstm_r2:.4f} \\\\\\\\\n",
    "            \\\\bottomrule\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\caption{{مقایسه عملکرد مدل‌های مختلف در پیش‌بینی قیمت بیت‌کوین با آزمون t جفت‌شده نسبت به LSTM}}\n",
    "        \\\\label{{tab:model_comparison}}\n",
    "    \\\\end{{table}}\n",
    "    \"\"\"\n",
    "    with open(r'latex\\chapters\\model_comparison_table.tex', 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_comparison_table)\n",
    "\n",
    "    # Generate Feature Importance Table for Tree-Based Models\n",
    "    feature_names = [f'Lag {i+1}' for i in range(7)] + ['MA7']\n",
    "    latex_feature_importance = f\"\"\"\n",
    "    \\\\begin{{table}}[h]\n",
    "        \\\\centering\n",
    "        \\\\begin{{tabular}}{{lccc}}\n",
    "            \\\\toprule\n",
    "            \\\\textbf{{ویژگی}} & \\\\textbf{{Gradient Boosting}} & \\\\textbf{{Random Forest}} & \\\\textbf{{XGBoost}} \\\\\\\\\n",
    "            \\\\midrule\n",
    "    \"\"\"\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        latex_feature_importance += f\"        {fname} & {gbr_model.feature_importances_[i]:.4f} & {rfr_model.feature_importances_[i]:.4f} & {xgb_model.feature_importances_[i]:.4f} \\\\\\\\\\n\"\n",
    "    latex_feature_importance += f\"\"\"\n",
    "            \\\\bottomrule\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\caption{{اهمیت ویژگی‌ها در مدل‌های مبتنی بر درخت (Gradient Boosting، Random Forest، XGBoost)}}\n",
    "        \\\\label{{tab:feature_importance}}\n",
    "    \\\\end{{table}}\n",
    "    \"\"\"\n",
    "    with open(r'latex\\chapters\\feature_importance_table.tex', 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd1dfddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-14091.988, Time=2.86 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-14096.215, Time=0.48 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-14096.271, Time=0.56 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-14096.218, Time=0.67 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-14097.829, Time=0.21 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-14094.333, Time=1.06 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 5.847 seconds\n",
      "\n",
      "Model Performance Comparison:\n",
      "ARIMA - MAE: 22068.6384, RMSE: 26600.0228, R2: -2.1119\n",
      "Linear Regression - MAE: 1303.4137, RMSE: 1832.4142, R2: 0.9852\n",
      "Gradient Boosting - MAE: 6098.2405, RMSE: 11970.7240, R2: 0.3698\n",
      "Random Forest - MAE: 6504.4641, RMSE: 12464.2005, R2: 0.3167\n",
      "SVR - MAE: 14635.8548, RMSE: 23734.6798, R2: -1.4776\n",
      "XGBoost - MAE: 6956.9256, RMSE: 12993.2411, R2: 0.2575\n",
      "LSTM - MAE: 0.0120, RMSE: 0.0200, R2: 0.8800\n"
     ]
    }
   ],
   "source": [
    "additional_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b9ad4",
   "metadata": {},
   "source": [
    "<h1>Adding Block Chain Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_blockchain_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    start_ts = int(pd.Timestamp(start_date).timestamp())\n",
    "    end_ts = int(pd.Timestamp(end_date).timestamp())\n",
    "    \n",
    "    # Fetch transaction count\n",
    "    tx_url = f\"https://api.blockchain.info/charts/n-transactions?timespan=5years&start={start_ts}&end={end_ts}&format=json\"\n",
    "    tx_response = requests.get(tx_url)\n",
    "    if tx_response.status_code != 200:\n",
    "        print(f\"Error fetching transaction data: Status code {tx_response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    tx_data = tx_response.json()\n",
    "    tx_df = pd.DataFrame(tx_data['values'])\n",
    "    tx_df['date'] = pd.to_datetime(tx_df['x'], unit='s')\n",
    "    tx_df.set_index('date', inplace=True)\n",
    "    tx_df = tx_df.rename(columns={'y': 'TxCount'})\n",
    "    \n",
    "    # Fetch trade volume (in BTC)\n",
    "    vol_url = f\"https://api.blockchain.info/charts/trade-volume?timespan=5years&start={start_ts}&end={end_ts}&format=json\"\n",
    "    vol_response = requests.get(vol_url)\n",
    "    if vol_response.status_code != 200:\n",
    "        print(f\"Error fetching volume data: Status code {vol_response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    vol_data = vol_response.json()\n",
    "    vol_df = pd.DataFrame(vol_data['values'])\n",
    "    vol_df['date'] = pd.to_datetime(vol_df['x'], unit='s')\n",
    "    vol_df.set_index('date', inplace=True)\n",
    "    vol_df = vol_df.rename(columns={'y': 'TxVolumeBTC'})\n",
    "    \n",
    "    # Merge and convert volume to USD using BTC price\n",
    "    blockchain_data = pd.merge(tx_df[['TxCount']], vol_df[['TxVolumeBTC']], left_index=True, right_index=True, how='outer')\n",
    "    blockchain_data = blockchain_data.resample('D').mean().interpolate()\n",
    "    \n",
    "    btc_price = fetch_btc_data(start_date, end_date)\n",
    "    if btc_price.empty or 'Close' not in btc_price.columns:\n",
    "        print(\"No valid BTC price data available for volume conversion\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # # Ensure single-level indices\n",
    "    # blockchain_data = blockchain_data.reset_index()\n",
    "    # btc_price_close = btc_price[['Close']].reset_index().set_index('Date')\n",
    "    \n",
    "    # # Align indices and join\n",
    "    # common_index = blockchain_data['date']\n",
    "    # btc_price_close = btc_price_close.reindex(common_index, method='ffill')\n",
    "    \n",
    "    # blockchain_data = blockchain_data.set_index('date').join(btc_price_close['Close'], how='left')\n",
    "    \n",
    "\n",
    "    # Flatten multi-level column headers\n",
    "    btc_price.columns = btc_price.columns.get_level_values(0)  # or combine both levels if needed\n",
    "\n",
    "    # Confirm 'Close' is now a normal column\n",
    "    print(btc_price.columns)  # Should include 'Close'\n",
    "                                    \n",
    "    # Set the index properly (if not already)\n",
    "    btc_price.index = pd.to_datetime(btc_price.index)\n",
    "\n",
    "    # Set your blockchain_data index too\n",
    "    blockchain_data.index = pd.to_datetime(blockchain_data.index)\n",
    "\n",
    "    # Reindex or join\n",
    "    blockchain_data = blockchain_data.join(btc_price[['Close']], how='left')\n",
    "    \n",
    "\n",
    "    # Ensure single-level indices\n",
    "    blockchain_data = blockchain_data.reset_index()\n",
    "    btc_price_close = btc_price[['Close']].reset_index().set_index('Date')\n",
    "\n",
    "    # Align indices and join\n",
    "    common_index = blockchain_data['date']\n",
    "\n",
    "    blockchain_data.index = pd.to_datetime(blockchain_data.index)\n",
    "\n",
    "    btc_price.index = pd.to_datetime(btc_price.index)\n",
    "\n",
    "    blockchain_data = blockchain_data.reindex(btc_price.index, method='ffill').fillna(method='bfill')\n",
    "\n",
    "\n",
    "    # Debug: Verify structure\n",
    "    print(\"Blockchain Data index levels:\", blockchain_data.index.nlevels)\n",
    "    print(\"Blockchain Data columns after join:\", blockchain_data.columns.tolist())\n",
    "    if 'Close' not in blockchain_data.columns:\n",
    "        print(\"Join failed to include 'Close' column. Data:\", blockchain_data.head())\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    blockchain_data['TxVolumeUSD'] = blockchain_data['TxVolumeBTC'] * blockchain_data['Close']\n",
    "    blockchain_data['BlockHeight'] = np.arange(500000, 500000 + len(blockchain_data))  # Approximate block height\n",
    "    \n",
    "    return blockchain_data[['BlockHeight', 'TxCount', 'TxVolumeUSD','TxVolumeBTC']]\n",
    "\n",
    "# 3. Preprocess Data with Blockchain Features\n",
    "def preprocess_data_with_blockchain(btc_data, blockchain_data):\n",
    "    if btc_data.empty or blockchain_data.empty:\n",
    "        print(\"Empty data provided to preprocess_data_with_blockchain\")\n",
    "        return (None,) * 12\n",
    "    btc_data = btc_data.fillna(method='ffill')\n",
    "    blockchain_data = blockchain_data.reindex(btc_data.index, method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    prices = btc_data['Close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "    \n",
    "    # Extract blockchain features\n",
    "    block_height = blockchain_data['BlockHeight'].values\n",
    "    tx_count = blockchain_data['TxCount'].values\n",
    "    tx_volume_usd = blockchain_data['TxVolumeUSD'].values\n",
    "    \n",
    "    # Combine Features\n",
    "    features = []\n",
    "    targets = prices_scaled[7:]\n",
    "    for i in range(len(prices_scaled) - 7):\n",
    "        lagged = prices_scaled[i:i+7].flatten()\n",
    "        ma7 = np.mean(prices_scaled[i:i+7])\n",
    "        blockchain_features = [block_height[i+7], tx_count[i+7], tx_volume_usd[i+7]]\n",
    "        features.append(np.append(np.append(lagged, ma7), blockchain_features))\n",
    "    features = np.array(features)\n",
    "    \n",
    "    total_samples = len(features)\n",
    "    train_size = int(total_samples * 0.7)\n",
    "    val_size = int(total_samples * 0.15)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "    \n",
    "    train_features = features[:train_size]\n",
    "    val_features = features[train_size:train_size + val_size]\n",
    "    test_features = features[train_size + val_size:]\n",
    "    train_targets = targets[:train_size]\n",
    "    val_targets = targets[train_size:train_size + val_size]\n",
    "    test_targets = targets[train_size + val_size:]\n",
    "    \n",
    "    return (train_features, val_features, test_features, \n",
    "            train_targets, val_targets, test_targets, \n",
    "            scaler, prices, btc_data, block_height, tx_count, tx_volume_usd)\n",
    "\n",
    "\n",
    "# 4. Volatility Analysis with GARCH(1,1)\n",
    "def volatility_analysis(data, test_size):\n",
    "    if data.empty or 'Close' not in data.columns:\n",
    "        print(\"No valid data for volatility analysis\")\n",
    "        return pd.Series(), pd.Series()\n",
    "    returns = data['Close'].pct_change().dropna() * 100\n",
    "    test_returns = returns[-test_size:]\n",
    "    train_returns = returns[:-test_size]\n",
    "    garch_model = arch_model(train_returns, vol='Garch', p=1, q=1, mean='Zero', dist='normal')\n",
    "    garch_fit = garch_model.fit(disp='off')\n",
    "    forecast = garch_fit.forecast(horizon=len(test_returns))\n",
    "    garch_volatility = np.sqrt(forecast.variance.values[-1, :])\n",
    "    realized_volatility = test_returns.rolling(window=7).std().dropna()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(realized_volatility.index, realized_volatility, label='Realized Volatility', color='blue')\n",
    "    plt.plot(realized_volatility.index, garch_volatility[:len(realized_volatility)], label='GARCH(1,1) Volatility', color='orange')\n",
    "    plt.title('Realized vs GARCH(1,1) Volatility for BTC')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Volatility (%)')\n",
    "    plt.legend()\n",
    "    plt.savefig('volatility_analysis.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return realized_volatility, garch_volatility[:len(realized_volatility)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0edc6d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>TxCount</th>\n",
       "      <th>TxVolumeBTC</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>241757.0</td>\n",
       "      <td>1.000380e+09</td>\n",
       "      <td>13657.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>340980.0</td>\n",
       "      <td>6.606965e+08</td>\n",
       "      <td>14982.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>395963.0</td>\n",
       "      <td>1.365239e+09</td>\n",
       "      <td>15201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>425008.0</td>\n",
       "      <td>1.059923e+09</td>\n",
       "      <td>15599.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>342707.0</td>\n",
       "      <td>1.311574e+09</td>\n",
       "      <td>17429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>239359.0</td>\n",
       "      <td>3.983614e+07</td>\n",
       "      <td>16717.173828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>272949.0</td>\n",
       "      <td>8.334204e+07</td>\n",
       "      <td>16552.572266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>265955.0</td>\n",
       "      <td>9.358288e+07</td>\n",
       "      <td>16642.341797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>291015.0</td>\n",
       "      <td>6.386757e+07</td>\n",
       "      <td>16602.585938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>8.571615e+07</td>\n",
       "      <td>16547.496094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   TxCount   TxVolumeBTC         Close\n",
       "0    2018-01-01  241757.0  1.000380e+09  13657.200195\n",
       "1    2018-01-02  340980.0  6.606965e+08  14982.099609\n",
       "2    2018-01-03  395963.0  1.365239e+09  15201.000000\n",
       "3    2018-01-04  425008.0  1.059923e+09  15599.200195\n",
       "4    2018-01-05  342707.0  1.311574e+09  17429.500000\n",
       "...         ...       ...           ...           ...\n",
       "1821 2022-12-27  239359.0  3.983614e+07  16717.173828\n",
       "1822 2022-12-28  272949.0  8.334204e+07  16552.572266\n",
       "1823 2022-12-29  265955.0  9.358288e+07  16642.341797\n",
       "1824 2022-12-30  291015.0  6.386757e+07  16602.585938\n",
       "1825 2022-12-31  242325.0  8.571615e+07  16547.496094\n",
       "\n",
       "[1826 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockchain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e525a0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>13657.200195</td>\n",
       "      <td>14112.200195</td>\n",
       "      <td>13154.700195</td>\n",
       "      <td>14112.200195</td>\n",
       "      <td>10291200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>14982.099609</td>\n",
       "      <td>15444.599609</td>\n",
       "      <td>13163.599609</td>\n",
       "      <td>13625.000000</td>\n",
       "      <td>16846600192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>15201.000000</td>\n",
       "      <td>15572.799805</td>\n",
       "      <td>14844.500000</td>\n",
       "      <td>14978.200195</td>\n",
       "      <td>16871900160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15599.200195</td>\n",
       "      <td>15739.700195</td>\n",
       "      <td>14522.200195</td>\n",
       "      <td>15270.700195</td>\n",
       "      <td>21783199744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>17429.500000</td>\n",
       "      <td>17705.199219</td>\n",
       "      <td>15202.799805</td>\n",
       "      <td>15477.200195</td>\n",
       "      <td>23840899072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>95795.515625</td>\n",
       "      <td>99884.570312</td>\n",
       "      <td>95137.882812</td>\n",
       "      <td>99297.695312</td>\n",
       "      <td>47054980873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>94164.859375</td>\n",
       "      <td>97294.843750</td>\n",
       "      <td>93310.742188</td>\n",
       "      <td>95704.976562</td>\n",
       "      <td>52419934565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-28</th>\n",
       "      <td>95163.929688</td>\n",
       "      <td>95525.898438</td>\n",
       "      <td>94014.289062</td>\n",
       "      <td>94160.187500</td>\n",
       "      <td>24107436185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-29</th>\n",
       "      <td>93530.226562</td>\n",
       "      <td>95174.875000</td>\n",
       "      <td>92881.789062</td>\n",
       "      <td>95174.054688</td>\n",
       "      <td>29635885267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>92643.210938</td>\n",
       "      <td>94903.320312</td>\n",
       "      <td>91317.132812</td>\n",
       "      <td>93527.195312</td>\n",
       "      <td>56188003691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2556 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price              Close          High           Low          Open  \\\n",
       "Ticker           BTC-USD       BTC-USD       BTC-USD       BTC-USD   \n",
       "Date                                                                 \n",
       "2018-01-01  13657.200195  14112.200195  13154.700195  14112.200195   \n",
       "2018-01-02  14982.099609  15444.599609  13163.599609  13625.000000   \n",
       "2018-01-03  15201.000000  15572.799805  14844.500000  14978.200195   \n",
       "2018-01-04  15599.200195  15739.700195  14522.200195  15270.700195   \n",
       "2018-01-05  17429.500000  17705.199219  15202.799805  15477.200195   \n",
       "...                  ...           ...           ...           ...   \n",
       "2024-12-26  95795.515625  99884.570312  95137.882812  99297.695312   \n",
       "2024-12-27  94164.859375  97294.843750  93310.742188  95704.976562   \n",
       "2024-12-28  95163.929688  95525.898438  94014.289062  94160.187500   \n",
       "2024-12-29  93530.226562  95174.875000  92881.789062  95174.054688   \n",
       "2024-12-30  92643.210938  94903.320312  91317.132812  93527.195312   \n",
       "\n",
       "Price            Volume  \n",
       "Ticker          BTC-USD  \n",
       "Date                     \n",
       "2018-01-01  10291200000  \n",
       "2018-01-02  16846600192  \n",
       "2018-01-03  16871900160  \n",
       "2018-01-04  21783199744  \n",
       "2018-01-05  23840899072  \n",
       "...                 ...  \n",
       "2024-12-26  47054980873  \n",
       "2024-12-27  52419934565  \n",
       "2024-12-28  24107436185  \n",
       "2024-12-29  29635885267  \n",
       "2024-12-30  56188003691  \n",
       "\n",
       "[2556 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39ba3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ARIMA Model\n",
    "def train_arima_model_with_block_chain(train_data, val_data, test_data, scaler):\n",
    "    if len(train_data) == 0 or len(val_data) == 0 or len(test_data) == 0:\n",
    "        print(\"Insufficient data for ARIMA model\")\n",
    "        return np.array([]), np.array([])\n",
    "    train_val_data = np.concatenate([train_data, val_data]).flatten()\n",
    "    model = auto_arima(train_val_data, seasonal=False, trace=True, error_action='ignore', suppress_warnings=True, stepwise=True, max_p=5, max_d=2, max_q=5)\n",
    "    forecast = model.predict(n_periods=len(test_data))\n",
    "    conf_int = model.predict(n_periods=len(test_data), return_conf_int=True, alpha=0.05)[1]\n",
    "    forecast_inv = scaler.inverse_transform(forecast.reshape(-1, 1))\n",
    "    conf_int_inv = scaler.inverse_transform(conf_int)\n",
    "    return forecast_inv, conf_int_inv\n",
    "\n",
    "# 8. LSTM Model with Blockchain Data\n",
    "async def train_lstm_model_async(train_features, val_features, test_features, train_targets, val_targets, test_targets):\n",
    "\n",
    "    if train_features is None or train_targets is None or test_features is None:\n",
    "        print(\"Invalid data for LSTM model\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # Remove rows with NaNs in all sets\n",
    "    def clean_nan(X, y):\n",
    "        mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y).flatten()\n",
    "        return X[mask], y[mask]\n",
    "\n",
    "    train_features, train_targets = clean_nan(train_features, train_targets)\n",
    "    val_features, val_targets = clean_nan(val_features, val_targets)\n",
    "    test_features, test_targets = clean_nan(test_features, test_targets)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_all = np.concatenate([train_features, val_features, test_features])\n",
    "    X_all_scaled = scaler.fit_transform(X_all)\n",
    "    train_features_scaled = X_all_scaled[:len(train_features)]\n",
    "    val_features_scaled = X_all_scaled[len(train_features):len(train_features)+len(val_features)]\n",
    "    test_features_scaled = X_all_scaled[-len(test_features):]\n",
    "\n",
    "    # Combine train and val\n",
    "    X_train_val = np.concatenate([train_features_scaled, val_features_scaled]) if len(val_features_scaled) > 0 else train_features_scaled\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()]) if len(val_targets) > 0 else train_targets.flatten()\n",
    "    X_test = test_features_scaled\n",
    "    y_test = test_targets.flatten()\n",
    "\n",
    "    # Check for NaNs before reshaping\n",
    "    print(\"NaNs in X_train_val:\", np.isnan(X_train_val).sum())\n",
    "    print(\"NaNs in y_train_val:\", np.isnan(y_train_val).sum())\n",
    "    print(\"NaNs in X_test:\", np.isnan(X_test).sum())\n",
    "\n",
    "    # Reshape for LSTM\n",
    "    timesteps = 1\n",
    "    n_features = X_train_val.shape[1]\n",
    "    X_train_val_reshaped = X_train_val.reshape((X_train_val.shape[0], timesteps, n_features))\n",
    "    X_test_reshaped = X_test.reshape((X_test.shape[0], timesteps, n_features))\n",
    "\n",
    "    print(\"X_train_val_reshaped:\", X_train_val_reshaped.shape)\n",
    "    print(\"y_train_val shape:\", y_train_val.shape)\n",
    "\n",
    "    # Build LSTM Model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(timesteps, n_features), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train\n",
    "    model.fit(X_train_val_reshaped, y_train_val, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_reshaped, verbose=0)\n",
    "    print(\"NaNs in prediction:\", np.isnan(y_pred).sum())\n",
    "\n",
    "    return y_pred, y_test\n",
    "\n",
    "async def train_lstm_model_async_old(train_features, val_features, test_features, train_targets, val_targets, test_targets):\n",
    "    if train_features is None or train_targets is None or test_features is None:\n",
    "        print(\"Invalid data for LSTM model\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # Combine train and val\n",
    "    X_train_val = np.concatenate([train_features, val_features]) if len(val_features) > 0 else train_features\n",
    "    y_train_val = np.concatenate([train_targets.flatten(), val_targets.flatten()]) if len(val_targets) > 0 else train_targets.flatten()\n",
    "\n",
    "    X_test = test_features\n",
    "    y_test = test_targets.flatten()\n",
    "\n",
    "    # Check for NaNs before reshaping\n",
    "    print(\"NaNs in X_train_val:\", np.isnan(X_train_val).sum())\n",
    "    print(\"NaNs in y_train_val:\", np.isnan(y_train_val).sum())\n",
    "    print(\"NaNs in X_test:\", np.isnan(X_test).sum())\n",
    "\n",
    "    # Reshape for LSTM\n",
    "    timesteps = 1\n",
    "    n_features = X_train_val.shape[1]\n",
    "    X_train_val_reshaped = X_train_val.reshape((X_train_val.shape[0], timesteps, n_features))\n",
    "    X_test_reshaped = X_test.reshape((X_test.shape[0], timesteps, n_features))\n",
    "\n",
    "    print(\"X_train_val_reshaped:\", X_train_val_reshaped.shape)\n",
    "    print(\"y_train_val shape:\", y_train_val.shape)\n",
    "\n",
    "    # Build LSTM Model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(timesteps, n_features), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train\n",
    "    model.fit(X_train_val_reshaped, y_train_val, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_reshaped, verbose=0)\n",
    "    print(\"NaNs in prediction:\", np.isnan(y_pred).sum())\n",
    "\n",
    "    return y_pred, y_test\n",
    "\n",
    "\n",
    "\n",
    "# 9. Evaluate Model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    if y_true is None or y_pred is None:\n",
    "        print(\"No data to evaluate\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # Flatten and stack into one array for filtering\n",
    "    y_true = np.array(y_true).reshape(-1)\n",
    "    y_pred = np.array(y_pred).reshape(-1)\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "\n",
    "    y_true_clean = y_true[mask]\n",
    "    y_pred_clean = y_pred[mask]\n",
    "\n",
    "    if len(y_true_clean) == 0:\n",
    "        print(\"No valid data after removing NaNs\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
    "    r2 = r2_score(y_true_clean, y_pred_clean)\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "# 10. Plot Individual Model Predictions\n",
    "def plot_individual_model(actual, predicted, model_name, conf_int=None):\n",
    "    if len(actual) == 0 or len(predicted) == 0:\n",
    "        print(f\"No data to plot for {model_name}\")\n",
    "        return\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(actual, label='Actual Prices', color='blue')\n",
    "    plt.plot(predicted, label=f'{model_name} Predictions', color='orange')\n",
    "    if conf_int is not None:\n",
    "        plt.fill_between(range(len(predicted)), conf_int[:, 0], conf_int[:, 1], color='green', alpha=0.2, label='Prediction Interval')\n",
    "    plt.title(f'{model_name} Predictions vs Actual BTC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{model_name.lower()}_predictions.png')\n",
    "    plt.close()\n",
    "\n",
    "async def main_block_chain():\n",
    "    # Fetch and preprocess data\n",
    "    btc_data = fetch_btc_data()\n",
    "    blockchain_data = fetch_blockchain_data()\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, prices, btc_full_data, block_height, tx_count, tx_volume_usd) = preprocess_data_with_blockchain(btc_data, blockchain_data)\n",
    "    \n",
    "\n",
    "    # Volatility Analysis\n",
    "    realized_volatility, garch_volatility = volatility_analysis(btc_full_data, len(test_targets))\n",
    "    \n",
    "    # ARIMA Model\n",
    "    arima_pred, arima_conf_int = train_arima_model_with_block_chain(train_targets.flatten(), val_targets.flatten(), test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(scaler.inverse_transform(test_targets), arima_pred)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, test_features, train_targets, val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "    \n",
    "    # LSTM Model with Blockchain Data\n",
    "    lstm_pred, lstm_true = await train_lstm_model_async(train_features, val_features, test_features, train_targets, val_targets, test_targets)\n",
    "    lstm_pred_inv = scaler.inverse_transform(lstm_pred)\n",
    "    lstm_true_inv = scaler.inverse_transform(lstm_true.reshape(-1, 1))\n",
    "    print(\"lstm_pred_inv shape:\", lstm_pred_inv.shape)\n",
    "    print(\"lstm_true_inv shape:\", lstm_true_inv.shape)\n",
    "    print(\"NaNs in lstm_pred_inv:\", np.isnan(lstm_pred_inv).sum())\n",
    "    print(\"NaNs in lstm_true_inv:\", np.isnan(lstm_true_inv).sum())\n",
    "    \n",
    "    lstm_mae, lstm_rmse, lstm_r2 = evaluate_model(lstm_true_inv, lstm_pred_inv)\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"LSTM (with Blockchain Data) - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot Predictions\n",
    "    plot_individual_model(lr_true_inv, arima_pred, \"ARIMA_blockchain\", arima_conf_int)\n",
    "    plot_individual_model(lr_true_inv, lr_pred_inv, \"LinearRegression_blockchain\")\n",
    "    plot_individual_model(lstm_true_inv, lstm_pred_inv, \"LSTM_blockchain\")\n",
    "\n",
    "    # Plot Performance Metrics Comparison\n",
    "    models_metrics = [\n",
    "        (\"ARIMA\", arima_mae, arima_rmse, arima_r2),\n",
    "        (\"Linear Regression\", lr_mae, lr_rmse, lr_r2),\n",
    "        (\"LSTM\", lstm_mae, lstm_rmse, lstm_r2)\n",
    "    ]\n",
    "    plot_performance_comparison(models_metrics,'blockchain_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0ea634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n",
      "Blockchain Data index levels: 1\n",
      "Blockchain Data columns after join: ['date', 'TxCount', 'TxVolumeBTC', 'Close']\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-14091.988, Time=1.21 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-14096.215, Time=0.25 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-14096.271, Time=0.28 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-14096.218, Time=0.40 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-14097.829, Time=0.12 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-14094.333, Time=0.54 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 2.810 seconds\n",
      "NaNs in X_train_val: 0\n",
      "NaNs in y_train_val: 0\n",
      "NaNs in X_test: 0\n",
      "X_train_val_reshaped: (2166, 1, 11)\n",
      "y_train_val shape: (2166,)\n",
      "NaNs in prediction: 0\n",
      "lstm_pred_inv shape: (383, 1)\n",
      "lstm_true_inv shape: (383, 1)\n",
      "NaNs in lstm_pred_inv: 0\n",
      "NaNs in lstm_true_inv: 0\n",
      "\n",
      "Model Performance Comparison:\n",
      "ARIMA - MAE: 22068.6384, RMSE: 26600.0228, R2: -2.1119\n",
      "Linear Regression - MAE: 1301.4418, RMSE: 1829.9178, R2: 0.9853\n",
      "LSTM (with Blockchain Data) - MAE: 2912.8805, RMSE: 4296.8728, R2: 0.9188\n"
     ]
    }
   ],
   "source": [
    "await main_block_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f368f",
   "metadata": {},
   "source": [
    "<h1>Adding Macro Economics features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f64718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. Fetch Additional Economic Data\n",
    "def fetch_economic_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    try:\n",
    "        # Fetch S&P 500 Index Data\n",
    "        sp500 = yf.download('^GSPC', start=start_date, end=end_date, interval='1d')[['Close']].rename(columns={'Close': 'SP500'})\n",
    "        if sp500.empty:\n",
    "            raise ValueError(\"No S&P 500 data fetched\")\n",
    "        if sp500.isna().any().any():\n",
    "            print(\"NaN values found in S&P 500 data:\", sp500.isna().sum())\n",
    "            sp500 = sp500.fillna(method='ffill').fillna(method='bfill')\n",
    "        sp500.index = pd.to_datetime(sp500.index)  # Ensure proper index type\n",
    "\n",
    "        # Fetch Federal Funds Rate from FRED\n",
    "        fed_rate = pdr.get_data_fred('FEDFUNDS', start=start_date, end=end_date)\n",
    "        fed_rate = fed_rate.rename(columns={'FEDFUNDS': 'InterestRate'})\n",
    "        fed_rate.index = pd.to_datetime(fed_rate.index)\n",
    "        fed_rate = fed_rate.resample('D').ffill()  # Resample to daily\n",
    "        if fed_rate.isna().any().any():\n",
    "            print(\"NaN values found in Federal Funds Rate data:\", fed_rate.isna().sum())\n",
    "            fed_rate = fed_rate.fillna(method='ffill').fillna(method='bfill')\n",
    "        fed_rate.index.name = None  # Fix: remove index name\n",
    "\n",
    "        # Fetch CPI Data from BLS API\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        data = {\n",
    "            \"seriesid\": [\"CUUR0000SA0\"],\n",
    "            \"startyear\": \"2018\",\n",
    "            \"endyear\": \"2024\",\n",
    "            \"registrationkey\": \"23b34ab4ad3d475987e20a56fd7c8020\"\n",
    "        }\n",
    "        response = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', json=data, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching CPI data from BLS: Status code {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        json_data = response.json()\n",
    "        if json_data['status'] != 'REQUEST_SUCCEEDED':\n",
    "            print(f\"Error fetching CPI data: {json_data['message']}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        cpi_data = []\n",
    "        for series in json_data['Results']['series']:\n",
    "            for item in series['data']:\n",
    "                year = int(item['year'])\n",
    "                month = int(item['period'][1:])\n",
    "                value = float(item['value'])\n",
    "                date = pd.Timestamp(year=year, month=month, day=1)\n",
    "                cpi_data.append({'date': date, 'CPI': value})\n",
    "\n",
    "        cpi_df = pd.DataFrame(cpi_data).set_index('date').sort_index()\n",
    "        cpi_df = cpi_df.resample('D').interpolate()\n",
    "        cpi_df['InflationRate'] = cpi_df['CPI'].pct_change(periods=365) * 100\n",
    "        if cpi_df.isna().any().any():\n",
    "            print(\"NaN values found in CPI data:\", cpi_df.isna().sum())\n",
    "            cpi_df = cpi_df.fillna(method='ffill').fillna(method='bfill')\n",
    "        cpi_df.index.name = None  # Fix: remove index name\n",
    "\n",
    "        # Align indexes for join\n",
    "        sp500.index.name = None\n",
    "        fed_rate.index.name = None\n",
    "        cpi_df.index.name = None\n",
    "\n",
    "        # Combine economic data\n",
    "        economic_data = sp500.join([cpi_df[['InflationRate', 'CPI']], fed_rate], how='outer')\n",
    "        if economic_data.isna().any().any():\n",
    "            print(\"NaN values found in economic_data:\", economic_data.isna().sum())\n",
    "            economic_data = economic_data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        return economic_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching economic data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    \n",
    "\n",
    "def preprocess_data_with_blockchain(btc_data, blockchain_data):\n",
    "    if btc_data.empty or blockchain_data.empty:\n",
    "        print(\"Empty data provided to preprocess_data_with_blockchain\")\n",
    "        return (None,) * 12\n",
    "\n",
    "    # Fetch economic data\n",
    "    economic_data = fetch_economic_data(btc_data.index[0].date(), btc_data.index[-1].date())\n",
    "    if economic_data.empty:\n",
    "        print(\"Empty economic data, proceeding with blockchain data only\")\n",
    "        combined_data = btc_data.join(blockchain_data, how='outer')\n",
    "    else:\n",
    "        combined_data = btc_data.join(blockchain_data, how='outer').join(economic_data, how='outer')\n",
    "\n",
    "    combined_data = combined_data.fillna(method='ffill').fillna(method='bfill')\n",
    "    if combined_data.isna().any().any():\n",
    "        print(\"NaN values found in combined_data after filling:\", combined_data.isna().sum())\n",
    "        return (None,) * 12\n",
    "\n",
    "    prices = combined_data['Close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "\n",
    "    block_height = combined_data['BlockHeight'].values\n",
    "    tx_count = combined_data['TxCount'].values\n",
    "    tx_volume_usd = combined_data['TxVolumeUSD'].values\n",
    "    inflation_rate = combined_data['InflationRate'].values\n",
    "    interest_rate = combined_data['InterestRate'].values\n",
    "    sp500 = combined_data['SP500'].values\n",
    "\n",
    "    features = []\n",
    "    targets = prices_scaled[7:]\n",
    "    for i in range(len(prices_scaled) - 7):\n",
    "        lagged = prices_scaled[i:i+7].flatten()\n",
    "        ma7 = np.mean(prices_scaled[i:i+7])\n",
    "        blockchain_features = [block_height[i+7], tx_count[i+7], tx_volume_usd[i+7]]\n",
    "        economic_features = [inflation_rate[i+7], interest_rate[i+7], sp500[i+7]]\n",
    "        features.append(np.append(np.append(np.append(lagged, ma7), blockchain_features), economic_features))\n",
    "    features = np.array(features)\n",
    "\n",
    "    if np.isnan(features).any() or np.isnan(targets).any():\n",
    "        print(\"NaN values found in features or targets:\", np.isnan(features).sum(), np.isnan(targets).sum())\n",
    "        return (None,) * 12\n",
    "\n",
    "    total_samples = len(features)\n",
    "    train_size = int(total_samples * 0.7)\n",
    "    val_size = int(total_samples * 0.15)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "\n",
    "    train_features = features[:train_size]\n",
    "    val_features = features[train_size:train_size + val_size]\n",
    "    test_features = features[train_size + val_size:]\n",
    "    train_targets = targets[:train_size]\n",
    "    val_targets = targets[train_size:train_size + val_size]\n",
    "    test_targets = targets[train_size + val_size:]\n",
    "\n",
    "    return (train_features, val_features, test_features, \n",
    "            train_targets, val_targets, test_targets, \n",
    "            scaler, prices, combined_data, block_height, tx_count, tx_volume_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b51bf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_economic_data(start_date='2018-01-01', end_date='2024-12-31'):\n",
    "    try:\n",
    "        # Fetch S&P 500 Index Data\n",
    "        sp500 = yf.download('^GSPC', start=start_date, end=end_date, interval='1d')[['Close']].rename(columns={'Close': 'SP500'})\n",
    "        if sp500.empty:\n",
    "            raise ValueError(\"No S&P 500 data fetched\")\n",
    "        if sp500.isna().any().any():\n",
    "            print(\"NaN values found in S&P 500 data:\", sp500.isna().sum())\n",
    "            sp500 = sp500.fillna(method='ffill').fillna(method='bfill')\n",
    "        sp500.index = pd.to_datetime(sp500.index)  # Ensure proper index type\n",
    "\n",
    "        # Fetch Federal Funds Rate from FRED\n",
    "        fed_rate = pdr.get_data_fred('FEDFUNDS', start=start_date, end=end_date)\n",
    "        fed_rate = fed_rate.rename(columns={'FEDFUNDS': 'InterestRate'})\n",
    "        fed_rate.index = pd.to_datetime(fed_rate.index)\n",
    "        fed_rate = fed_rate.resample('D').ffill()  # Resample to daily\n",
    "        if fed_rate.isna().any().any():\n",
    "            print(\"NaN values found in Federal Funds Rate data:\", fed_rate.isna().sum())\n",
    "            fed_rate = fed_rate.fillna(method='ffill').fillna(method='bfill')\n",
    "        fed_rate.index.name = None  # Fix: remove index name\n",
    "\n",
    "        # Fetch CPI Data from BLS API\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        data = {\n",
    "            \"seriesid\": [\"CUUR0000SA0\"],\n",
    "            \"startyear\": \"2018\",\n",
    "            \"endyear\": \"2024\",\n",
    "            \"registrationkey\": \"23b34ab4ad3d475987e20a56fd7c8020\"\n",
    "        }\n",
    "        response = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', json=data, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching CPI data from BLS: Status code {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        json_data = response.json()\n",
    "        if json_data['status'] != 'REQUEST_SUCCEEDED':\n",
    "            print(f\"Error fetching CPI data: {json_data['message']}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        cpi_data = []\n",
    "        for series in json_data['Results']['series']:\n",
    "            for item in series['data']:\n",
    "                year = int(item['year'])\n",
    "                month = int(item['period'][1:])\n",
    "                value = float(item['value'])\n",
    "                date = pd.Timestamp(year=year, month=month, day=1)\n",
    "                cpi_data.append({'date': date, 'CPI': value})\n",
    "\n",
    "        cpi_df = pd.DataFrame(cpi_data).set_index('date').sort_index()\n",
    "        cpi_df = cpi_df.resample('D').interpolate()\n",
    "        cpi_df['InflationRate'] = cpi_df['CPI'].pct_change(periods=365) * 100\n",
    "        if cpi_df.isna().any().any():\n",
    "            print(\"NaN values found in CPI data:\", cpi_df.isna().sum())\n",
    "            cpi_df = cpi_df.fillna(method='ffill').fillna(method='bfill')\n",
    "        cpi_df.index.name = None  # Fix: remove index name\n",
    "\n",
    "        # Align indexes for join\n",
    "        sp500.index.name = None\n",
    "        fed_rate.index.name = None\n",
    "        cpi_df.index.name = None\n",
    "\n",
    "        # Combine economic data\n",
    "        economic_data = sp500.join([cpi_df[['InflationRate', 'CPI']], fed_rate], how='outer')\n",
    "        if economic_data.isna().any().any():\n",
    "            print(\"NaN values found in economic_data:\", economic_data.isna().sum())\n",
    "            economic_data = economic_data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        return economic_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching economic data: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518f21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c59cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values found in CPI data: CPI                0\n",
      "InflationRate    365\n",
      "dtype: int64\n",
      "NaN values found in economic_data: (SP500, ^GSPC)    787\n",
      "InflationRate      20\n",
      "CPI                20\n",
      "InterestRate       20\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(SP500, ^GSPC)</th>\n",
       "      <th>InflationRate</th>\n",
       "      <th>CPI</th>\n",
       "      <th>InterestRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>2695.810059</td>\n",
       "      <td>1.551235</td>\n",
       "      <td>247.867000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>2695.810059</td>\n",
       "      <td>1.551235</td>\n",
       "      <td>247.903258</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>2713.060059</td>\n",
       "      <td>1.551235</td>\n",
       "      <td>247.939516</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>2723.989990</td>\n",
       "      <td>1.551235</td>\n",
       "      <td>247.975774</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>2743.149902</td>\n",
       "      <td>1.551235</td>\n",
       "      <td>248.012032</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>5974.069824</td>\n",
       "      <td>2.869980</td>\n",
       "      <td>315.605000</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>6040.040039</td>\n",
       "      <td>2.869980</td>\n",
       "      <td>315.605000</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>6037.589844</td>\n",
       "      <td>2.869980</td>\n",
       "      <td>315.605000</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>5970.839844</td>\n",
       "      <td>2.869980</td>\n",
       "      <td>315.605000</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>5906.939941</td>\n",
       "      <td>2.869980</td>\n",
       "      <td>315.605000</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2547 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            (SP500, ^GSPC)  InflationRate         CPI  InterestRate\n",
       "2018-01-01     2695.810059       1.551235  247.867000          1.41\n",
       "2018-01-02     2695.810059       1.551235  247.903258          1.41\n",
       "2018-01-03     2713.060059       1.551235  247.939516          1.41\n",
       "2018-01-04     2723.989990       1.551235  247.975774          1.41\n",
       "2018-01-05     2743.149902       1.551235  248.012032          1.41\n",
       "...                    ...            ...         ...           ...\n",
       "2024-12-23     5974.069824       2.869980  315.605000          4.48\n",
       "2024-12-24     6040.040039       2.869980  315.605000          4.48\n",
       "2024-12-26     6037.589844       2.869980  315.605000          4.48\n",
       "2024-12-27     5970.839844       2.869980  315.605000          4.48\n",
       "2024-12-30     5906.939941       2.869980  315.605000          4.48\n",
       "\n",
       "[2547 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_economic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c344006",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main_economic_data():\n",
    "    btc_data = fetch_btc_data()\n",
    "    if btc_data.empty:\n",
    "        print(\"Failed to fetch BTC data, aborting execution\")\n",
    "        return\n",
    "    blockchain_data = fetch_blockchain_data()\n",
    "    if blockchain_data.empty:\n",
    "        print(\"Failed to fetch blockchain data, aborting execution\")\n",
    "        return\n",
    "    (train_features, val_features, test_features,\n",
    "     train_targets, val_targets, test_targets,\n",
    "     scaler, prices, combined_data, block_height, tx_count, tx_volume_usd) = preprocess_data_with_blockchain(btc_data, blockchain_data)\n",
    "\n",
    "    if train_features is None:\n",
    "        print(\"Preprocessing failed, aborting execution\")\n",
    "        return\n",
    "\n",
    "    realized_volatility, garch_volatility = volatility_analysis(combined_data, len(test_targets))\n",
    "\n",
    "    arima_pred, arima_conf_int = train_arima_model_with_block_chain(train_targets.flatten(), val_targets.flatten(), test_targets.flatten(), scaler)\n",
    "    arima_mae, arima_rmse, arima_r2 = evaluate_model(scaler.inverse_transform(test_targets), arima_pred)\n",
    "\n",
    "    lr_pred, lr_true = train_linear_regression(train_features, val_features, test_features, train_targets, val_targets, test_targets)\n",
    "    lr_pred_inv = scaler.inverse_transform(lr_pred.reshape(-1, 1))\n",
    "    lr_true_inv = scaler.inverse_transform(lr_true.reshape(-1, 1))\n",
    "    lr_mae, lr_rmse, lr_r2 = evaluate_model(lr_true_inv, lr_pred_inv)\n",
    "\n",
    "    lstm_pred, lstm_true = await train_lstm_model_async(train_features, val_features, test_features, train_targets, val_targets, test_targets)\n",
    "    lstm_pred_inv = scaler.inverse_transform(lstm_pred)\n",
    "    lstm_true_inv = scaler.inverse_transform(lstm_true.reshape(-1, 1))\n",
    "    lstm_mae, lstm_rmse, lstm_r2 = evaluate_model(lstm_true_inv, lstm_pred_inv)\n",
    "\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"ARIMA - MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, R2: {arima_r2:.4f}\")\n",
    "    print(f\"Linear Regression - MAE: {lr_mae:.4f}, RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n",
    "    print(f\"LSTM (with Blockchain and Economic Data) - MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, R2: {lstm_r2:.4f}\")\n",
    "\n",
    "    plot_individual_model(lr_true_inv, arima_pred, \"ARIMA_economic_data\", arima_conf_int)\n",
    "    plot_individual_model(lr_true_inv, lr_pred_inv, \"LinearRegression_economic_data\")\n",
    "    plot_individual_model(lstm_true_inv, lstm_pred_inv, \"LSTM_economic_data\")\n",
    "     # Plot Performance Metrics Comparison\n",
    "    models_metrics = [\n",
    "        (\"ARIMA\", arima_mae, arima_rmse, arima_r2),\n",
    "        (\"Linear Regression\", lr_mae, lr_rmse, lr_r2),\n",
    "        (\"LSTM\", lstm_mae, lstm_rmse, lstm_r2)\n",
    "    ]\n",
    "    plot_performance_comparison(models_metrics,'economic_data')\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31c369d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n",
      "Blockchain Data index levels: 1\n",
      "Blockchain Data columns after join: ['date', 'TxCount', 'TxVolumeBTC', 'Close']\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-14091.988, Time=1.05 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-14096.215, Time=0.24 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-14096.271, Time=0.23 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-14096.218, Time=0.31 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-14097.829, Time=0.10 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-14094.333, Time=0.40 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 2.341 seconds\n",
      "NaNs in X_train_val: 0\n",
      "NaNs in y_train_val: 0\n",
      "NaNs in X_test: 0\n",
      "X_train_val_reshaped: (2166, 1, 11)\n",
      "y_train_val shape: (2166,)\n",
      "NaNs in prediction: 0\n",
      "\n",
      "Model Performance Comparison:\n",
      "ARIMA - MAE: 22068.6384, RMSE: 26600.0228, R2: -2.1119\n",
      "Linear Regression - MAE: 1301.4418, RMSE: 1829.9178, R2: 0.9853\n",
      "LSTM (with Blockchain and Economic Data) - MAE: 8927.3946, RMSE: 10492.9766, R2: 0.5158\n"
     ]
    }
   ],
   "source": [
    "await main_economic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01cee0",
   "metadata": {},
   "source": [
    "<h1>Description of Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ba3b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "btc_data = fetch_btc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8c1caa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2556.000000</td>\n",
       "      <td>2556.000000</td>\n",
       "      <td>2556.000000</td>\n",
       "      <td>2556.000000</td>\n",
       "      <td>2.556000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28060.072129</td>\n",
       "      <td>28650.847219</td>\n",
       "      <td>27380.998146</td>\n",
       "      <td>28031.100705</td>\n",
       "      <td>2.695372e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22106.145509</td>\n",
       "      <td>22560.377180</td>\n",
       "      <td>21575.174321</td>\n",
       "      <td>22073.164851</td>\n",
       "      <td>1.965635e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3236.761719</td>\n",
       "      <td>3275.377930</td>\n",
       "      <td>3191.303467</td>\n",
       "      <td>3236.274658</td>\n",
       "      <td>2.923670e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8975.989502</td>\n",
       "      <td>9202.108154</td>\n",
       "      <td>8792.074707</td>\n",
       "      <td>8940.944092</td>\n",
       "      <td>1.380814e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22185.371094</td>\n",
       "      <td>22598.989258</td>\n",
       "      <td>21453.022461</td>\n",
       "      <td>22013.654297</td>\n",
       "      <td>2.405443e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42840.408203</td>\n",
       "      <td>43575.499023</td>\n",
       "      <td>41906.514648</td>\n",
       "      <td>42807.783203</td>\n",
       "      <td>3.536010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>106140.601562</td>\n",
       "      <td>108268.445312</td>\n",
       "      <td>105291.734375</td>\n",
       "      <td>106147.296875</td>\n",
       "      <td>3.509679e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price           Close           High            Low           Open  \\\n",
       "Ticker        BTC-USD        BTC-USD        BTC-USD        BTC-USD   \n",
       "count     2556.000000    2556.000000    2556.000000    2556.000000   \n",
       "mean     28060.072129   28650.847219   27380.998146   28031.100705   \n",
       "std      22106.145509   22560.377180   21575.174321   22073.164851   \n",
       "min       3236.761719    3275.377930    3191.303467    3236.274658   \n",
       "25%       8975.989502    9202.108154    8792.074707    8940.944092   \n",
       "50%      22185.371094   22598.989258   21453.022461   22013.654297   \n",
       "75%      42840.408203   43575.499023   41906.514648   42807.783203   \n",
       "max     106140.601562  108268.445312  105291.734375  106147.296875   \n",
       "\n",
       "Price         Volume  \n",
       "Ticker       BTC-USD  \n",
       "count   2.556000e+03  \n",
       "mean    2.695372e+10  \n",
       "std     1.965635e+10  \n",
       "min     2.923670e+09  \n",
       "25%     1.380814e+10  \n",
       "50%     2.405443e+10  \n",
       "75%     3.536010e+10  \n",
       "max     3.509679e+11  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0cff6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"describe_btc_data.tex\", \"w\") as f:\n",
    "    f.write(btc_data.describe().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fae3ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n",
      "Blockchain Data index levels: 1\n",
      "Blockchain Data columns after join: ['date', 'TxCount', 'TxVolumeBTC', 'Close']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "blockchain_data = fetch_blockchain_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18aa97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"describe_blockchain_data.tex\", \"w\") as f:\n",
    "    f.write(blockchain_data.describe().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76af90fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockHeight</th>\n",
       "      <th>TxCount</th>\n",
       "      <th>TxVolumeUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2556.000000</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>2.556000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>501277.500000</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>1.418388e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>737.997967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.958197e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500000.000000</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>1.418388e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500638.750000</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>1.418388e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>501277.500000</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>1.418388e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>501916.250000</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>1.418388e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>502555.000000</td>\n",
       "      <td>242325.0</td>\n",
       "      <td>1.418388e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BlockHeight   TxCount   TxVolumeUSD\n",
       "count    2556.000000    2556.0  2.556000e+03\n",
       "mean   501277.500000  242325.0  1.418388e+12\n",
       "std       737.997967       0.0  5.958197e-02\n",
       "min    500000.000000  242325.0  1.418388e+12\n",
       "25%    500638.750000  242325.0  1.418388e+12\n",
       "50%    501277.500000  242325.0  1.418388e+12\n",
       "75%    501916.250000  242325.0  1.418388e+12\n",
       "max    502555.000000  242325.0  1.418388e+12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockchain_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145266b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
